# 텔레그램 추가 차트 시스템 분석 문서 (v2.1)

**문서 버전**: v2.1 (중복 CSV 제거 + 리포트/차트 역할 정리)
**작성일**: 2025-12-10
**최종 업데이트**: 2025-12-14
**관련 커밋**: `48932dcd371e38b95ec1cac5be3c6ec00268db54` (STOM_V1 머지)
**대상 브랜치**: `main` (기능 개발: `STOM_V1` / `feature/backtesting_result_update`)
**관련 파일**:
- `backtester/back_static.py` - 메인 분석 호출
- `backtester/back_analysis_enhanced.py` - 강화된 분석 모듈 (NEW)
- `utility/setting.py` - `GRAPH_PATH` (차트/CSV 저장 경로)

---

## 1. 개요

### 1.1 목적

백테스팅 결과에서 매수/매도 시점의 상세 시장 데이터를 분석하여 다음 정보를 텔레그램으로 전송합니다:

1. **기본 분석 차트**: 시간대별, 등락율별, 체결강도별 수익 분포 시각화
2. **강화된 필터 분석**: 통계적 유의성 검증 + 효과 크기 측정 (NEW)
3. **필터 조합 분석**: 다중 필터 시너지 효과 분석 (NEW)
4. **ML 특성 중요도**: Decision Tree 기반 변수 중요도 (NEW)
5. **동적 임계값 탐색**: 최적 필터 임계값 자동 탐색 (NEW)
6. **필터 안정성 검증**: 기간별 일관성 분석 (NEW)
7. **조건식 코드 생성**: 실제 적용 가능한 코드 자동 생성 (NEW)

### 1.2 v2.0 주요 개선 사항

| 영역 | v1.0 | v2.0 |
|------|------|------|
| **필터 분석** | 단일 필터만 분석 | 필터 조합 시너지 분석 |
| **통계 검증** | 없음 | t-test, Cohen's d, 신뢰구간 |
| **특성 분석** | 상관관계만 | ML 기반 특성 중요도 |
| **임계값** | 고정값 | 동적 최적값 탐색 |
| **안정성** | 없음 | 기간별 일관성 검증 |
| **코드 생성** | 없음 | 조건식 자동 생성 |
| **파생 지표** | 10개 | 27개 (모멘텀/리스크/연속손익/품질 등) |

### 1.3 v2.1 개선 사항 (중복 제거/역할 정리)

1. **CSV 중복 생성 제거**
   - 기존: `detail.csv` + `enhanced_detail.csv` 동시 생성, `filter.csv` + `filter_analysis.csv` 동시 생성
   - 변경: **강화 분석이 사용 가능한 경우** `detail.csv`/`filter.csv`를 강화 분석 결과로 **단일화**
     - `*_enhanced_detail.csv`, `*_filter_analysis.csv`는 더 이상 생성하지 않음
     - 강화 분석 실패 시에만 기본 `detail.csv`/`filter.csv`로 폴백 생성
2. **텔레그램 추가 차트 3종 역할 분리**
   - `*_analysis.png`: **백테스팅 결과 분석 차트** (매수 시각 X축 `HH:MM`, 거래대금 단위: 백만, 시가총액 X축: 100억 단위 + 1조 이상은 조 표기)
   - `*_comparison.png`: **매수/매도 시점 상세 비교 차트** (x축 tick 세분화, 위험도 점수별 수익금 분포, 보유시간 분 단위 산점도 포함)
   - `*_enhanced.png`: **필터 기능 분석 차트** (통계/시너지/안정성/임계값/코드 생성 + Top 15 파레토 차트 포함)
3. **산출물 리포트(txt) 자동 생성**
   - `{save_file_name}_report.txt`에 생성 파일 목록/생성시각/조건식/요약 정보를 함께 저장

### 1.4 시스템 아키텍처

```
┌─────────────────────────────────────────────────────────────────────┐
│                     백테스팅 엔진 (BackEngine)                        │
│  ┌─────────────────────────────────────────────────────────────┐    │
│  │  CalculationEyun()                                          │    │
│  │  • 매수 시점 시장 데이터 수집 (20개 컬럼)                      │    │
│  │  • 매도 시점 시장 데이터 수집 (16개 컬럼)                      │    │
│  └─────────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────────┐
│                      결과 처리 (back_static.py)                      │
│  ┌─────────────────────────────────────────────────────────────┐    │
│  │  PltShow()                                                  │    │
│  │  └─→ RunEnhancedAnalysis() [NEW - back_analysis_enhanced.py]│    │
│  │       │                                                     │    │
│  │       ├─→ CalculateEnhancedDerivedMetrics()                │    │
│  │       │   • 모멘텀/리스크/연속손익/거래품질 등 27개 파생 지표   │    │
│  │       │                                                     │    │
│  │       ├─→ AnalyzeFilterEffectsEnhanced()                   │    │
│  │       │   • t-test, Cohen's d, 95% 신뢰구간                 │    │
│  │       │                                                     │    │
│  │       ├─→ FindAllOptimalThresholds()                       │    │
│  │       │   • 분위수 기반 최적 임계값 탐색                      │    │
│  │       │                                                     │    │
│  │       ├─→ AnalyzeFilterCombinations()                      │    │
│  │       │   • 2-3개 필터 조합 시너지 분석                      │    │
│  │       │                                                     │    │
│  │       ├─→ AnalyzeFeatureImportance()                       │    │
│  │       │   • Decision Tree 기반 Gini 중요도                  │    │
│  │       │                                                     │    │
│  │       ├─→ AnalyzeFilterStability()                         │    │
│  │       │   • 5개 기간 분할 일관성 검증                        │    │
│  │       │                                                     │    │
│  │       ├─→ GenerateFilterCode()                             │    │
│  │       │   • 조건식 코드 자동 생성                            │    │
│  │       │                                                     │    │
│  │       └─→ PltEnhancedAnalysisCharts()                      │    │
│  │           • 14개 강화된 시각화 차트                          │    │
│  └─────────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────────┐
│                       텔레그램 전송 (teleQ)                          │
│  • 이미지 1: {전략명}.png              (기본 수익곡선)               │
│  • 이미지 2: {전략명}_.png             (부가정보)                    │
│  • 이미지 3: {전략명}_enhanced.png     (강화된 분석 - 14개 차트) NEW │
│  • 텍스트: 통계적 유의 필터 추천                                     │
│  • 텍스트: 조합 필터 추천                                            │
│  • 텍스트: 자동 생성 조건식 코드                                     │
│  • CSV 최대 8개: (기본 3개 + 강화 5개)                               │
└─────────────────────────────────────────────────────────────────────┘
```

---

## 2. 강화된 파생 지표 (CalculateEnhancedDerivedMetrics)

### 2.1 함수 개요

파일: `backtester/back_analysis_enhanced.py`

```python
def CalculateEnhancedDerivedMetrics(df_tsg):
    """
    강화된 파생 지표를 계산합니다.

    기본 파생지표 14개 + 강화 신규 13개 = 총 27개 파생 지표
    """
```

### 2.2 신규 파생 지표

#### 모멘텀 점수 (NEW)

```python
# 등락율과 체결강도를 정규화하여 모멘텀 점수 계산
등락율_norm = (df['매수등락율'] - df['매수등락율'].mean()) / df['매수등락율'].std()
체결강도_norm = (df['매수체결강도'] - 100) / 50  # 100을 기준으로 정규화
df['모멘텀점수'] = round((등락율_norm * 0.4 + 체결강도_norm * 0.6) * 10, 2)
```

**해석**:
- 양수: 상승 모멘텀
- 음수: 하락 모멘텀
- 절대값이 클수록 강한 모멘텀

#### 변동성 지표 (NEW)

```python
df['매수변동폭비율'] = (df['매수고가'] - df['매수저가']) / df['매수저가'] * 100
df['매도변동폭비율'] = (df['매도고가'] - df['매도저가']) / df['매도저가'] * 100
df['변동성변화'] = df['매도변동폭비율'] - df['매수변동폭비율']
```

**해석**:
- 양수: 보유 중 변동성 증가 (위험 증가)
- 음수: 보유 중 변동성 감소 (안정화)

#### 거래 품질 점수 (NEW)

```python
df['거래품질점수'] = 50  # 기본값

# 긍정적 요소 가산
df.loc[df['매수체결강도'] >= 120, '거래품질점수'] += 10
df.loc[df['매수체결강도'] >= 150, '거래품질점수'] += 10
df.loc[df['매수호가잔량비'] >= 100, '거래품질점수'] += 10
df.loc[(df['시가총액'] >= 1000) & (df['시가총액'] <= 10000), '거래품질점수'] += 10

# 부정적 요소 감산
df.loc[df['매수등락율'] >= 25, '거래품질점수'] -= 15
df.loc[df['매수등락율'] >= 30, '거래품질점수'] -= 10
df.loc[df['매수스프레드'] >= 0.5, '거래품질점수'] -= 10

df['거래품질점수'] = df['거래품질점수'].clip(0, 100)
```

**해석**:
- 0-30점: 낮은 품질 (피해야 할 거래)
- 30-50점: 보통 품질
- 50-70점: 좋은 품질
- 70-100점: 우수한 품질

#### 리스크 조정 수익률 (NEW)

```python
# 수익률을 위험 요소로 나누어 조정
risk_factor = (df['매수등락율'].abs() / 10 + df['보유시간'] / 300 + 1)
df['리스크조정수익률'] = round(df['수익률'] / risk_factor, 4)
```

**해석**:
- 같은 수익률이라도 위험이 낮을수록 높은 값
- Sharpe Ratio와 유사한 개념

#### 시간대 타이밍 점수 (NEW)

```python
# 시간대별 평균 수익률 기반 타이밍 점수
hour_profit = df.groupby('매수시')['수익률'].mean()
df['시간대평균수익률'] = df['매수시'].map(hour_profit)
df['타이밍점수'] = (df['시간대평균수익률'] - mean) / std * 10
```

**해석**:
- 양수: 유리한 시간대에 매수
- 음수: 불리한 시간대에 매수

### 2.3 전체 파생 지표 목록

| 번호 | 지표명 | 유형 | 설명 |
|------|--------|------|------|
| 1 | 등락율변화 | 변화량 | 매도등락율 - 매수등락율 |
| 2 | 체결강도변화 | 변화량 | 매도체결강도 - 매수체결강도 |
| 3 | 전일비변화 | 변화량 | 매도전일비 - 매수전일비 |
| 4 | 회전율변화 | 변화량 | 매도회전율 - 매수회전율 |
| 5 | 호가잔량비변화 | 변화량 | 매도호가잔량비 - 매수호가잔량비 |
| 6 | 거래대금변화율 | 변화율 | 매도거래대금 / 매수거래대금 |
| 7 | 체결강도변화율 | 변화율 | 매도체결강도 / 매수체결강도 |
| 8 | 등락추세 | 범주형 | 상승/하락/유지 |
| 9 | 체결강도추세 | 범주형 | 강화/약화/유지 |
| 10 | 거래량추세 | 범주형 | 증가/감소/유지 |
| 11 | 급락신호 | 불리언 | 등락율↓3% AND 체결강도↓20 |
| 12 | 매도세증가 | 불리언 | 호가잔량비↓0.2 |
| 13 | 거래량급감 | 불리언 | 거래대금변화율 < 0.5 |
| 14 | 위험도점수 | 0-100점 | 종합 위험 점수 (강화됨) |
| 15 | **이익여부** | 불리언 | `수익금 > 0` (ML 타겟 변수) |
| 16 | **모멘텀점수** | 연속값 | 등락율+체결강도 정규화 |
| 17 | **매수변동폭** | 연속값 | 매수 시점 고가-저가 |
| 18 | **매수변동폭비율** | % | (매수고가-매수저가)/매수가 × 100 |
| 19 | **매도변동폭비율** | % | (매도고가-매도저가)/매도가 × 100 |
| 20 | **변동성변화** | % | 매도변동폭비율 - 매수변동폭비율 |
| 21 | **스프레드영향** | 연속값 | 매수스프레드가 수익률에 미치는 패널티(정규화) |
| 22 | **시간대평균수익률** | % | 동일 매수시(시간대) 평균 수익률 |
| 23 | **타이밍점수** | 연속값 | 시간대평균수익률을 Z-score로 정규화 |
| 24 | **리스크조정수익률** | % | 수익률 / (위험요소 가중치) |
| 25 | **거래품질점수** | 0-100점 | 체결강도/거래대금/스프레드 등 종합 품질 |
| 26 | **연속이익** | 정수 | 직전 거래까지의 연속 이익 횟수 |
| 27 | **연속손실** | 정수 | 직전 거래까지의 연속 손실 횟수 |

---

## 3. 통계적 유의성 검증 (CalculateStatisticalSignificance)

### 3.1 함수 개요

파일: `backtester/back_analysis_enhanced.py`

```python
def CalculateStatisticalSignificance(filtered_out, remaining):
    """
    필터 효과의 통계적 유의성을 계산합니다.

    Returns:
        dict: {
            't_stat': t-통계량,
            'p_value': p-값,
            'effect_size': Cohen's d,
            'confidence_interval': 95% 신뢰구간,
            'significant': p < 0.05 여부
        }
    """
```

### 3.2 통계 검정 방법

#### Welch's t-test

```python
# 두 그룹 (제외 거래 vs 남은 거래)의 수익금 차이 검정
t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)
```

**해석**:
- p < 0.05: 통계적으로 유의한 차이 존재
- p < 0.01: 매우 유의한 차이
- p >= 0.05: 우연에 의한 차이일 가능성

#### Cohen's d 효과 크기

```python
pooled_std = np.sqrt((np.var(group1) + np.var(group2)) / 2)
effect_size = (np.mean(group1) - np.mean(group2)) / pooled_std
```

**해석 기준**:

| 효과 크기 | Cohen's d | 의미 |
|-----------|-----------|------|
| 무시 | < 0.2 | 실질적 차이 없음 |
| 작음 | 0.2 - 0.5 | 작은 효과 |
| 중간 | 0.5 - 0.8 | 중간 효과 |
| 큼 | 0.8 - 1.2 | 큰 효과 |
| 매우 큼 | > 1.2 | 매우 큰 효과 |

#### 95% 신뢰구간

```python
mean_diff = np.mean(group1) - np.mean(group2)
se = np.sqrt(np.var(group1)/len(group1) + np.var(group2)/len(group2))
ci_low = mean_diff - 1.96 * se
ci_high = mean_diff + 1.96 * se
```

**해석**:
- 신뢰구간이 0을 포함하지 않으면 유의한 차이
- 구간이 좁을수록 추정 정확도 높음

### 3.3 권장 등급 개선

```python
# v2.0 개선된 권장 등급 로직
if improvement > total_profit * 0.15 and significant:
    rating = '★★★'  # 강력 추천 (유의하고 개선율 15% 이상)
elif improvement > total_profit * 0.05 and p_value < 0.1:
    rating = '★★'   # 추천 (약간 유의하고 개선율 5% 이상)
elif improvement > 0:
    rating = '★'    # 고려 (개선 있음)
else:
    rating = ''     # 비추천
```

---

## 4. 동적 최적 임계값 탐색 (FindOptimalThresholds)

### 4.1 함수 개요

```python
def FindOptimalThresholds(df_tsg, column, direction='less', n_splits=20):
    """
    특정 컬럼에 대해 최적의 필터 임계값을 탐색합니다.

    Args:
        column: 분석할 컬럼 (예: '매수등락율')
        direction: 'less' (미만 제외) 또는 'greater' (이상 제외)
        n_splits: 분할 수 (기본 20개 분위수)

    Returns:
        최적 임계값 및 효과 정보
    """
```

### 4.2 알고리즘

```python
# 1. 분위수 기반 임계값 생성 (5% ~ 95%)
percentiles = np.linspace(5, 95, n_splits)
thresholds = np.percentile(values, percentiles)

# 2. 각 임계값에 대해 수익 개선 효과 계산
for threshold in thresholds:
    if direction == 'less':
        condition = df_tsg[column] < threshold
    else:
        condition = df_tsg[column] >= threshold

    improvement = -filtered_out['수익금'].sum()
    efficiency = improvement / len(filtered_out)  # 거래당 효율

# 3. 최적 임계값 선택 (제외비율 50% 이하에서 효율 최대)
best = df_valid[df_valid['efficiency'] == df_valid['efficiency'].max()]
```

### 4.3 분석 대상 컬럼

```python
columns_config = [
    ('매수등락율', 'greater', '등락율 {:.0f}% 이상 제외'),
    ('매수등락율', 'less', '등락율 {:.0f}% 미만 제외'),
    ('매수체결강도', 'less', '체결강도 {:.0f} 미만 제외'),
    ('매수체결강도', 'greater', '체결강도 {:.0f} 이상 제외'),
    ('매수당일거래대금', 'less', '거래대금 {:.0f}억 미만 제외'),
    ('시가총액', 'less', '시가총액 {:.0f}억 미만 제외'),
    ('시가총액', 'greater', '시가총액 {:.0f}억 이상 제외'),
    ('보유시간', 'less', '보유시간 {:.0f}초 미만 제외'),
    ('보유시간', 'greater', '보유시간 {:.0f}초 이상 제외'),
    ('매수호가잔량비', 'less', '호가잔량비 {:.0f}% 미만 제외'),
    ('매수스프레드', 'greater', '스프레드 {:.2f}% 이상 제외'),
    ('위험도점수', 'greater', '위험도 {:.0f}점 이상 제외'),
    ('거래품질점수', 'less', '거래품질 {:.0f}점 미만 제외'),
]
```

### 4.4 출력 예시

```csv
column,direction,optimal_threshold,improvement,excluded_ratio,efficiency
매수등락율,greater,22.5,1250000,8.5,147059
매수체결강도,less,85,890000,6.2,143548
시가총액,less,850,720000,5.8,124138
```

---

## 5. 필터 조합 분석 (AnalyzeFilterCombinations)

### 5.1 함수 개요

```python
def AnalyzeFilterCombinations(df_tsg, max_filters=3, top_n=10):
    """
    필터 조합의 시너지 효과를 분석합니다.

    시너지 = 조합 개선 - 개별 개선 합
    - 양수 시너지: 조합이 개별보다 효과적
    - 음수 시너지: 중복 효과로 비효율
    """
```

### 5.2 시너지 효과 계산

```python
# OR 조건으로 조합 (둘 중 하나라도 해당되면 제외)
combined_condition = cond1 | cond2

filtered_out = df_tsg[combined_condition]
improvement = -filtered_out['수익금'].sum()

# 시너지 = 조합 효과 - 개별 효과 합
individual_sum = filter1['improvement'] + filter2['improvement']
synergy = improvement - individual_sum
synergy_ratio = synergy / individual_sum * 100
```

### 5.3 해석

| 시너지 비율 | 의미 | 권장 |
|-------------|------|------|
| > 20% | 강한 시너지 (상호 보완) | ★★★ |
| 0 ~ 20% | 약한 시너지 | ★★ |
| < 0% | 중복 효과 (비효율) | 비추천 |

### 5.4 출력 예시

```csv
조합유형,필터1,필터2,개별개선합,조합개선,시너지효과,시너지비율,권장
2개 조합,등락율 25% 이상 제외,체결강도 80 미만 제외,1250000,1580000,330000,26.4%,★★★
2개 조합,시간대 14시 제외,보유시간 30초 미만 제외,890000,920000,30000,3.4%,★★
```

---

## 6. ML 특성 중요도 (AnalyzeFeatureImportance)

### 6.1 함수 개요

```python
def AnalyzeFeatureImportance(df_tsg):
    """
    Decision Tree를 사용하여 특성 중요도를 분석합니다.

    Returns:
        feature_importance: Gini 중요도 순위
        decision_rules: 주요 분기 규칙
        model_accuracy: 모델 정확도
    """
```

### 6.2 알고리즘

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler

# 특성 선택
feature_columns = [
    '매수등락율', '매수체결강도', '매수당일거래대금', '매수전일비',
    '매수회전율', '시가총액', '보유시간', '매수호가잔량비'
]

# 타겟: 이익 여부 (이진 분류)
y = (df_tsg['수익금'] > 0).astype(int)

# Decision Tree 학습
clf = DecisionTreeClassifier(max_depth=4, min_samples_leaf=10)
clf.fit(X_scaled, y)

# Gini 중요도 추출
importance = dict(zip(feature_columns, clf.feature_importances_))
```

### 6.3 분기 규칙 추출

```python
# 상위 2레벨의 분기 규칙 추출
rules = [{
    'feature': '매수등락율',
    'threshold': 18.5,
    'left_win_rate': 62.3,   # 18.5% 미만
    'right_win_rate': 41.2,  # 18.5% 이상
    'rule': '매수등락율 < 18.5: 승률 62.3%'
}]
```

### 6.4 출력 예시

```
=== ML 특성 중요도 (정확도: 65.2%) ===

1. 매수등락율     : 0.285 ████████████████████
2. 매수체결강도   : 0.198 ██████████████
3. 보유시간       : 0.156 ███████████
4. 시가총액       : 0.142 ██████████
5. 매수당일거래대금: 0.089 ██████
```

---

## 7. 필터 안정성 검증 (AnalyzeFilterStability)

### 7.1 함수 개요

```python
def AnalyzeFilterStability(df_tsg, n_periods=5):
    """
    필터 효과의 시간적 안정성을 검증합니다.

    Args:
        n_periods: 분할 기간 수 (기본 5개)

    Returns:
        일관성 점수 및 안정성 등급
    """
```

### 7.2 안정성 점수 계산

```python
# 5개 기간으로 분할하여 각 기간별 필터 효과 계산
for period_df in periods:
    improvement = -filtered_out['수익금'].sum()
    period_improvements.append(improvement)

# 일관성 점수 계산
positive_periods = sum(1 for x in improvements if x > 0)
consistency_score = (positive_periods / n_periods) * 50

# 변동계수 반영
if mean_improvement > 0:
    cv = std_improvement / mean_improvement
    consistency_score += max(0, 50 - cv * 50)
```

### 7.3 안정성 등급

| 일관성 점수 | 등급 | 의미 |
|-------------|------|------|
| >= 70 | 안정 | 모든 기간에서 일관된 효과 |
| 40-70 | 보통 | 대부분 기간에서 효과 있음 |
| < 40 | 불안정 | 기간별 변동 큼 (신뢰도 낮음) |

### 7.4 출력 예시

```csv
분류,필터명,평균개선,표준편차,양수기간수,일관성점수,안정성등급
등락율,매수등락율 >= 20,285000,42000,5,82.5,안정
체결강도,매수체결강도 < 80,180000,95000,4,58.3,보통
보유시간,보유시간 < 60,120000,180000,3,35.2,불안정
```

---

## 8. 조건식 코드 자동 생성 (GenerateFilterCode)

### 8.1 함수 개요

```python
def GenerateFilterCode(filter_results, top_n=5):
    """
    필터 분석 결과를 실제 적용 가능한 조건식 코드로 변환합니다.

    Returns:
        code_text: 주석 포함 코드 텍스트
        buy_conditions: 매수 조건 리스트
        individual_conditions: 개별 조건 상세
    """
```

### 8.2 생성 코드 예시

```python
# ===== 자동 생성된 필터 조건 (백테스팅 분석 기반) =====

# [매수등락율] 필터
# - 매수등락율 22% 이상 제외: 수익개선 1,250,000원, 제외율 8.5%

# [매수체결강도] 필터
# - 매수체결강도 85 미만 제외: 수익개선 890,000원, 제외율 6.2%

# [시가총액] 필터
# - 시가총액 850억 미만 제외: 수익개선 720,000원, 제외율 5.8%

# ===== 적용 예시 =====
# 기존 매수 조건에 다음 필터를 AND 조건으로 추가:
#
# if 기존매수조건
#     and 매수등락율 < 22
#     and 매수체결강도 >= 85
#     and 시가총액 >= 850
#     매수 = True
```

---

## 9. 강화된 시각화 차트 (PltEnhancedAnalysisCharts)

### 9.1 생성되는 16개 차트

| 위치 | 차트명 | 설명 |
|------|--------|------|
| gs[0,0:2] | 필터 효과 순위 | Top 10 필터 수평 막대 그래프 |
| gs[0,2] | 통계적 유의성 분포 | 유의/비유의 파이 차트 |
| gs[1,0] | ML 특성 중요도 | Gini 중요도 막대 그래프 |
| gs[1,1] | 효과 크기 분포 | Cohen's d 히스토그램 |
| gs[1,2] | 필터 적용 시 예상 수익 개선 효과 (Top 15) | 개선금액 막대 + 누적비율(파레토) |
| gs[2,0] | 필터 안정성 Top 10 | 기간별 일관성 점수 상위 필터 |
| gs[2,1] | 최적 임계값 요약 (Top) | 임계값/제외비율/개선/효율 테이블 |
| gs[2,2] | 필터 조합 시너지 Top | 상위 조합 텍스트 요약 |
| gs[3,0] | **거래품질 점수별** | 품질 점수 구간별 (NEW) |
| gs[3,1] | **위험도 점수별** | 위험도 구간별 (ENHANCED) |
| gs[3,2] | **리스크조정수익률 분포** | 분포 히스토그램 (NEW) |
| gs[4,0:2] | 필터 결과 요약 (Top) | 개선/제외/p값/효과/권장 테이블 |
| gs[4,2] | 조건식 코드 생성 | 자동 생성 코드 요약 + 스니펫 |
| gs[5,0] | 필터 조합 시너지 히트맵 | Top 조합 기반 Heatmap (NEW) |
| gs[5,1] | 임계값 효율성 곡선 | 제외비율 대비 효율성 곡선 (NEW) |
| gs[5,2] | 분석 요약 | 텍스트 요약 정보 |

### 9.2 출력 파일

```
파일: backtester/graph/{전략명}_enhanced.png
크기: 20x30 인치 (2400x3600 픽셀)
해상도: 120 DPI
```

---

## 10. CSV 출력 파일

### 10.1 공통 사항 (저장 경로/인코딩/규칙)

- **저장 경로**: `utility/setting.py`의 `GRAPH_PATH` (기본값: `./backtester/graph`)
- **파일명 규칙**: `{save_file_name}_{suffix}.csv`
  - `{save_file_name}`는 백테스터에서 전달되는 저장 베이스명(전략명/기간/옵션 포함)
  - `{suffix}`는 아래 표의 `_detail`, `_summary`, `_filter`, `_optimal_thresholds` 등
  - (v2.1) `*_enhanced_detail.csv`, `*_filter_analysis.csv`는 **중복 생성 이슈로 제거**되고 `*_detail.csv`, `*_filter.csv`로 통합되었습니다.
- **인코딩**: `utf-8-sig` (Excel에서 한글/기호 깨짐 최소화를 위해 BOM 포함)
- **구분자/개행**: `,` / `\n` (기본 pandas `to_csv` 출력)
- **인덱스 컬럼 포함 여부**
  - `*_detail.csv`: `index=True` → **첫 번째 컬럼이 DataFrame 인덱스**
  - 그 외 CSV: `index=False`

### 10.2 기본 CSV (RunFullAnalysis / ExportBacktestCSV)

기본 분석은 `backtester/back_static.py`의 `RunFullAnalysis()` → `ExportBacktestCSV()` 경로에서 생성됩니다.

| 파일명 | 생성 함수 | 내용 | 비고 |
|--------|----------|------|------|
| `{전략명}_detail.csv` | `ExportBacktestCSV()` | 전체 거래 상세 + 기본 파생지표(최대 14개) | 인덱스 포함 |
| `{전략명}_summary.csv` | `ExportBacktestCSV()` | 조건별 요약 통계(시간대/등락율구간/체결강도구간/매도조건) | 인덱스 미포함 |
| `{전략명}_filter.csv` | `AnalyzeFilterEffects()` | 단일 필터 제외 시 예상 수익 개선 효과(간이 분석) | 인덱스 미포함 |

#### 10.2.1 `{전략명}_detail.csv` 컬럼 구성

`detail.csv`는 백테스팅 “거래 1건 = 행 1개” 형태의 원본 결과에, `CalculateDerivedMetrics()`가 계산한 기본 파생지표가 추가된 형태입니다.

- (v2.1) **강화 분석 사용 시**: `RunEnhancedAnalysis()`가 동일 파일명(`*_detail.csv`)에 **강화 파생지표(추가 13개)**를 포함해 저장합니다. 이때 기본 분석 경로의 `detail.csv` 생성은 **중복 방지로 생략**됩니다.
- (폴백) 강화 분석이 실패하거나 비활성인 경우: 기존과 동일하게 기본 파생지표만 포함된 `detail.csv`가 생성됩니다.

- **기본 거래 정보(공통)**
  - `종목명`, `매수시간`, `매도시간`, `보유시간`, `매수가`, `매도가`, `매수금액`, `매도금액`, `수익률`, `수익금`, `수익금합계`, `매도조건`, `추가매수시간`
- **주식/코인 컬럼 차이**
  - 주식(`ui_gubun` != `CT/CF`): `시가총액`
  - 코인(`ui_gubun` in `CT/CF`): `포지션`
- **매수 시점 시장 스냅샷(20개)**: `매수일자`, `매수시`, `매수분`, `매수초`, `매수등락율`, `매수시가등락율`, `매수당일거래대금`, `매수체결강도`, `매수전일비`, `매수회전율`, `매수전일동시간비`, `매수고가`, `매수저가`, `매수고저평균대비등락율`, `매수매도총잔량`, `매수매수총잔량`, `매수호가잔량비`, `매수매도호가1`, `매수매수호가1`, `매수스프레드`
- **매도 시점 시장 스냅샷(16개)**: `매도등락율`, `매도시가등락율`, `매도당일거래대금`, `매도체결강도`, `매도전일비`, `매도회전율`, `매도전일동시간비`, `매도고가`, `매도저가`, `매도고저평균대비등락율`, `매도매도총잔량`, `매도매수총잔량`, `매도호가잔량비`, `매도매도호가1`, `매도매수호가1`, `매도스프레드`

##### (참고) `utility/setting.py` 컬럼 스키마(원본)

- 주식(`columns_bt`)

```csv
종목명,시가총액,매수시간,매도시간,보유시간,매수가,매도가,매수금액,매도금액,수익률,수익금,수익금합계,매도조건,추가매수시간,매수일자,매수시,매수분,매수초,매수등락율,매수시가등락율,매수당일거래대금,매수체결강도,매수전일비,매수회전율,매수전일동시간비,매수고가,매수저가,매수고저평균대비등락율,매수매도총잔량,매수매수총잔량,매수호가잔량비,매수매도호가1,매수매수호가1,매수스프레드,매도등락율,매도시가등락율,매도당일거래대금,매도체결강도,매도전일비,매도회전율,매도전일동시간비,매도고가,매도저가,매도고저평균대비등락율,매도매도총잔량,매도매수총잔량,매도호가잔량비,매도매도호가1,매도매수호가1,매도스프레드
```

- 코인(`columns_btf`)

```csv
종목명,포지션,매수시간,매도시간,보유시간,매수가,매도가,매수금액,매도금액,수익률,수익금,수익금합계,매도조건,추가매수시간,매수일자,매수시,매수분,매수초,매수등락율,매수시가등락율,매수당일거래대금,매수체결강도,매수전일비,매수회전율,매수전일동시간비,매수고가,매수저가,매수고저평균대비등락율,매수매도총잔량,매수매수총잔량,매수호가잔량비,매수매도호가1,매수매수호가1,매수스프레드,매도등락율,매도시가등락율,매도당일거래대금,매도체결강도,매도전일비,매도회전율,매도전일동시간비,매도고가,매도저가,매도고저평균대비등락율,매도매도총잔량,매도매수총잔량,매도호가잔량비,매도매도호가1,매도매수호가1,매도스프레드
```

- `detail.csv`는 위 원본 스키마 뒤에 파생지표 컬럼이 추가됩니다. (v2.1: 강화 분석 사용 시 강화 파생지표까지 포함)
- **기본 파생지표(최대 14개)**: `등락율변화`, `체결강도변화`, `전일비변화`, `회전율변화`, `호가잔량비변화`, `거래대금변화율`, `체결강도변화율`, `등락추세`, `체결강도추세`, `거래량추세`, `급락신호`, `매도세증가`, `거래량급감`, `위험도점수`
  - 매도 시점 컬럼이 모두 존재하지 않으면(`매도등락율` 등 6개) 파생지표는 계산되지 않고 원본 컬럼만 저장됩니다.

#### 10.2.2 `{전략명}_summary.csv` 컬럼 정의

| 컬럼 | 의미 |
|------|------|
| `분류` | 요약 기준을 나타내는 카테고리(예: `시간대별`, `등락율구간별`, `체결강도구간별`, `매도조건별`) |
| `조건` | 해당 분류에서의 세부 조건 값(예: `9시`, `10-15%`, `100-120`, 특정 `매도조건` 문자열) |
| `거래횟수` | 해당 조건에 속하는 거래 수 |
| `승률` | `수익금 > 0` 비율(%) |
| `총수익금` | 해당 조건 거래들의 `수익금` 합 |
| `평균수익률` | 해당 조건 거래들의 `수익률` 평균 |
| `평균보유시간` | 해당 조건 거래들의 `보유시간` 평균(초) |
| `손실거래비중` | `수익금 < 0` 비율(%) |

#### 10.2.3 `{전략명}_filter.csv` 컬럼 정의

`filter.csv`는 “어떤 조건(필터)을 적용해 해당 거래를 제외하면 손익이 얼마나 개선되는가”를 빠르게 비교하기 위한 표입니다.

- (v2.1) **강화 분석 사용 시**: `RunEnhancedAnalysis()`가 동일 파일명(`*_filter.csv`)에 **통계 검정/효과 크기/조건식/적용코드**까지 포함한 확장 스키마로 저장합니다. 이때 기본 분석 경로의 `filter.csv` 생성은 **중복 방지로 생략**됩니다.
- (폴백) 강화 분석이 실패하거나 비활성인 경우: 간이 스키마(아래 표)로 `filter.csv`가 생성됩니다.

| 컬럼 | 의미 |
|------|------|
| `분류` | 필터 카테고리(예: `시간대`, `등락율`, `체결강도`, `추세변화`, `위험신호`) |
| `필터명` | 필터 설명(예: `등락율 25% 이상 제외`) |
| `제외거래수` | 필터 조건에 걸려 제외되는 거래 수 |
| `제외비율` | `제외거래수 / 전체거래수 × 100` |
| `제외거래수익금` | 제외된 거래들의 `수익금` 합 |
| `잔여거래수` | 필터 적용 후 남는 거래 수 |
| `잔여거래수익금` | 남은 거래들의 `수익금` 합 |
| `수익개선금액` | `-(제외거래수익금)` (제외된 거래가 손실일수록 개선값이 커짐) |
| `제외거래승률` | 제외된 거래의 승률(%) |
| `잔여거래승률` | 잔여 거래의 승률(%) |
| `적용권장` | 간단 등급(개선 효과 기준 별표) |

### 10.3 강화 CSV (RunEnhancedAnalysis)

강화 분석은 `backtester/back_analysis_enhanced.py`의 `RunEnhancedAnalysis()`에서 생성되며, 일부 파일은 분석 결과가 없으면 생성되지 않을 수 있습니다.

| 파일명 | 내용 | 비고 |
|--------|------|------|
| `{전략명}_detail.csv` | 전체 거래 상세 + 강화 파생지표(기본+강화) | (v2.1) 강화 분석 결과로 통합 저장 |
| `{전략명}_filter.csv` | 강화된 단일 필터 분석(통계 포함) | (v2.1) 강화 분석 결과로 통합 저장 |
| `{전략명}_optimal_thresholds.csv` | 컬럼별 동적 최적 임계값 탐색 결과 | 임계값 테이블 |
| `{전략명}_filter_combinations.csv` | 2~3개 필터 조합 시너지 분석 | 조합 테이블 |
| `{전략명}_filter_stability.csv` | 기간 분할 기반 필터 안정성 | 안정성 테이블 |

#### 10.3.1 `{전략명}_detail.csv` (강화 모드) 컬럼 참고

강화 분석이 활성화된 경우 `detail.csv`는 **기본 파생지표 + 강화 파생지표**가 모두 포함된 “단일 상세 파일”로 저장됩니다.

- 기본 파생지표(14개)는 `10.2.1` 참고
- 강화 파생지표(추가분)는 `2.3 전체 파생 지표 목록`의 15~27번 참고

#### 10.3.2 `{전략명}_filter.csv` (강화 모드) 컬럼 정의

강화 분석이 활성화된 경우 `filter.csv`는 `AnalyzeFilterEffectsEnhanced()` 결과를 저장하며, “개선 효과 + 통계적 유의성 + 효과 크기 + 코드 스니펫”까지 함께 제공합니다.

```csv
분류,필터명,조건식,적용코드,제외거래수,제외비율,제외거래수익금,제외평균수익률,잔여거래수,잔여거래수익금,잔여평균수익률,수익개선금액,제외거래승률,잔여거래승률,t통계량,p값,효과크기,효과해석,신뢰구간,유의함,적용권장
```

- `조건식`: DataFrame(`df_tsg`)에 대해 평가 가능한 파이썬 조건식 문자열
- `적용코드`: 실제 매수/필터 로직에 옮기기 쉬운 코드 조각
- `t통계량/p값/신뢰구간`: Welch t-test 기반(3장 참고)
- `효과크기/효과해석`: Cohen’s d 기반(3장 참고)

#### 10.3.3 `{전략명}_optimal_thresholds.csv` 컬럼 정의

| 컬럼 | 의미 |
|------|------|
| `column` | 탐색 대상 컬럼명(예: `매수등락율`) |
| `direction` | 필터 방향(`less`: 미만 제외 / `greater`: 이상 제외) |
| `optimal_threshold` | 선택된 최적 임계값 |
| `improvement` | 해당 임계값에서의 수익 개선 금액 |
| `excluded_ratio` | 해당 임계값 적용 시 제외 비율(%) |
| `excluded_count` | 제외 거래 수 |
| `remaining_winrate` | 남은 거래 승률(%) |
| `efficiency` | 제외 거래 1건당 개선 효과(가중 지표) |
| `all_thresholds` | 내부 탐색 전체 결과(리스트) — CSV에서는 문자열로 저장 |
| `필터명` | 사람이 읽기 쉬운 필터 설명(문구 템플릿) |

#### 10.3.4 `{전략명}_filter_combinations.csv` 컬럼 정의

| 컬럼 | 의미 |
|------|------|
| `조합유형(필터개수)` | `2개 조합` 또는 `3개 조합` |
| `필터1/필터2/필터3` | 조합된 필터명 |
| `개별개선합(원=각필터단독개선합)` | 개별 필터 수익개선금액의 합 |
| `조합개선(원=조합적용개선금액)` | OR 조건으로 조합했을 때의 개선 금액 |
| `시너지효과(원=조합개선-개별개선합)` | `조합개선 - 개별개선합` |
| `시너지비율(%=시너지효과/개별개선합)` | `시너지효과 / 개별개선합 × 100` |
| `제외비율(%=조합적용시제외)` | 조합 적용 시 제외 비율(%) |
| `잔여승률(%=조합적용후)` | 조합 적용 후 잔여 거래 승률(%) |
| `잔여거래수(건)` | 잔여 거래 수 |
| `권장(시너지기준)` | 시너지 비율 기반 간단 등급 |

- (v2.1) `{전략명}_filter_combinations.csv`는 `조합개선(원=조합적용개선금액)` 내림차순(동률 시 `시너지효과` 내림차순)으로 정렬됩니다.

#### 10.3.5 `{전략명}_filter_stability.csv` 컬럼 정의

| 컬럼 | 의미 |
|------|------|
| `분류` | 필터 카테고리 |
| `필터명` | 안정성 평가 대상 필터명 |
| `평균개선` | 기간별 개선값의 평균 |
| `표준편차` | 기간별 개선값의 표준편차 |
| `양수기간수/총기간수` | 개선이 양수인 기간 수 / 전체 기간 수 |
| `일관성점수` | 0~100 (양수 기간 비율 + 변동계수 기반) |
| `기간별개선` | 각 기간 개선 금액 리스트 — CSV에서는 문자열로 저장 |
| `안정성등급` | `안정`/`보통`/`불안정` |

### 10.4 CSV 분석 팁 (Excel/파이썬)

- **Excel**: `utf-8-sig`이므로 일반적으로 바로 열리지만, 열 분리가 깨지면 “데이터 → 텍스트/CSV”로 가져오고 구분자를 `,`로 지정
- **파이썬(리스트 컬럼 파싱)**: `all_thresholds`, `기간별개선`은 문자열이므로 필요 시 `ast.literal_eval()`로 리스트로 복원

### 10.5 산출물 리포트(txt) (v2.1)

백테스팅 실행 1회에 대해, 생성된 CSV/PNG 목록과 조건식/요약 정보를 **단일 텍스트 파일로 함께 저장**합니다.

- **파일명**: `{전략명}_report.txt`
- **저장 위치**: `backtester/graph/`
- **인코딩**: `utf-8-sig`

리포트에 포함되는 대표 항목:

- 실행 메타: 생성 시각, `save_file_name`, 백테스트 구분, 기간/시간, Seed, MDD, 강화 분석 성공/실패 여부
- 조건식: 매수/매도 조건식 문자열(`buy_vars`, `sell_vars`) 원문
- 성과 요약: 거래 수, 총 수익금, 승률, 평균 수익률, 매도조건 상위(빈도)
- 추천 요약: 기본/강화 분석 추천 Top N
- 생성 파일 목록: 파일명, 파일 크기(bytes), mtime(수정 시각), 산출물 설명

---

## 11. 텔레그램 전송 내용

### 11.1 전송 순서 (v2.1)

1. **텍스트**: `"{전략명} {날짜} 완료."`
2. **이미지**: `{전략명}_.png` (부가정보 차트)
3. **이미지**: `{전략명}.png` (수익곡선 차트)
4. **이미지**: `{전략명}_analysis.png` (백테스팅 결과 분석 차트)
5. **이미지**: `{전략명}_comparison.png` (매수/매도 시점 상세 비교 차트)
6. **이미지**: `{전략명}_enhanced.png` (필터 기능 분석 차트 - 16개)
7. **텍스트**: 필터 추천/조합 추천/안정성 요약
8. **텍스트**: 자동 생성 조건식 요약

※ CSV/PNG 생성 목록은 `{전략명}_report.txt`로 `backtester/graph`에 저장되며, 기본 설정에서는 텔레그램으로 전송하지 않습니다.

### 11.2 메시지 예시 (v2.1)

```
강화된 필터 분석 결과:

[통계적 유의] 매수등락율 22% 이상 제외: +1,250,000원 (p=0.008)
[통계적 유의] 매수체결강도 85 미만 제외: +890,000원 (p=0.023)
[조합추천] 매수등락율 22% 이상 + 매수체결강도 85 미만: 시너지 +330,000원
[안정성] 매수등락율 >= 20: 일관성 82.5점

자동 생성 필터 코드:
총 3개 필터
예상 총 개선: 2,860,000원
```

---

## 12. 전략 개선 프로세스 (v2.0)

### 12.1 분석 기반 의사결정 흐름

```
1. 백테스팅 실행
     │
     ▼
2. 강화된 분석 결과 확인
     │
     ├── 통계적 유의성 확인
     │    • p < 0.05 필터만 신뢰
     │    • 효과 크기 '중간' 이상 권장
     │
     ├── 필터 조합 시너지 확인
     │    • 시너지 비율 > 20% 조합 우선
     │    • 중복 효과 조합 피하기
     │
     ├── ML 특성 중요도 확인
     │    • 중요도 높은 변수 필터 우선
     │    • 분기 규칙 참고
     │
     ├── 필터 안정성 확인
     │    • '안정' 등급 필터만 적용
     │    • '불안정' 필터는 추가 검증
     │
     ▼
3. 자동 생성 코드 활용
     │
     ├── 조건식 복사/붙여넣기
     │
     ▼
4. 재백테스팅
     │
     ▼
5. 개선 효과 검증
```

### 12.2 신뢰도 높은 필터 선택 기준

**적용 추천 조건 (모두 충족 시)**:
- ✅ 통계적으로 유의함 (p < 0.05)
- ✅ 효과 크기 '중간' 이상 (Cohen's d > 0.5)
- ✅ 안정성 등급 '안정' (일관성 > 70)
- ✅ 제외 비율 30% 이하 (거래 기회 유지)
- ✅ 수익 개선 > 총수익 × 5%

---

## 13. 관련 파일 요약 (v2.0)

| 파일 | 함수/클래스 | 역할 |
|------|------------|------|
| `back_static.py` | `PltShow()` | 메인 차트 생성 + 강화 분석 호출 |
| `back_analysis_enhanced.py` | `CalculateEnhancedDerivedMetrics()` | 27개 파생 지표 계산 |
| `back_analysis_enhanced.py` | `CalculateStatisticalSignificance()` | t-test, Cohen's d |
| `back_analysis_enhanced.py` | `AnalyzeFilterEffectsEnhanced()` | 통계 포함 필터 분석 |
| `back_analysis_enhanced.py` | `FindOptimalThresholds()` | 최적 임계값 탐색 |
| `back_analysis_enhanced.py` | `FindAllOptimalThresholds()` | 모든 컬럼 임계값 탐색 |
| `back_analysis_enhanced.py` | `AnalyzeFilterCombinations()` | 필터 조합 시너지 |
| `back_analysis_enhanced.py` | `AnalyzeFeatureImportance()` | ML 특성 중요도 |
| `back_analysis_enhanced.py` | `AnalyzeFilterStability()` | 기간별 안정성 |
| `back_analysis_enhanced.py` | `GenerateFilterCode()` | 조건식 코드 생성 |
| `back_analysis_enhanced.py` | `PltEnhancedAnalysisCharts()` | 16개 강화 차트 |
| `back_analysis_enhanced.py` | `RunEnhancedAnalysis()` | 전체 강화 분석 실행 |

---

## 부록 A: 의존성 요구사항

```python
# 기본 (기존)
numpy
pandas
matplotlib

# 통계 (NEW)
scipy  # t-test, 정규분포

# 머신러닝 (NEW - 선택적)
scikit-learn  # DecisionTreeClassifier, StandardScaler
```

---

## 부록 B: 성능 고려사항

| 분석 단계 | 시간 복잡도 | 예상 시간 (1000거래) |
|-----------|-------------|---------------------|
| 파생 지표 계산 | O(n) | < 1초 |
| 단일 필터 분석 | O(n × m) | 2-3초 |
| 최적 임계값 탐색 | O(n × m × 20) | 5-10초 |
| 필터 조합 분석 | O(n × C(m,2)) | 10-20초 |
| ML 특성 중요도 | O(n × log n) | 2-3초 |
| 안정성 분석 | O(n × m × 5) | 5-10초 |
| 차트 생성 | O(n) | 3-5초 |
| **총 시간** | - | **약 30-50초** |

---

## 부록 C: 버전 히스토리

| 버전 | 날짜 | 변경 사항 |
|------|------|----------|
| v1.0 | 2025-12-09 | 초기 문서 (기본 분석) |
| v2.0 | 2025-12-10 | 강화된 분석 기능 추가 |

---

*문서 끝*
