# 11. 최적화 가이드

> Optuna, 유전 알고리즘, Walk-Forward Test를 활용한 전략 최적화

## 목차

- [최적화 기초](#최적화-기초)
- [Optuna 최적화](#optuna-최적화)
- [유전 알고리즘](#유전-알고리즘)
- [Walk-Forward Test](#walk-forward-test)
- [과최적화 방지](#과최적화-방지)

---

## 최적화 기초

### 최적화란?

**전략의 파라미터를 자동으로 조정하여 성능을 극대화하는 과정**

예시:
```python
# 최적화 전
ma_short = 5
ma_long = 20

# 최적화 후
ma_short = 7  # 5 → 7로 변경
ma_long = 23  # 20 → 23으로 변경
# 수익률 15% → 25% 향상!
```

### 최적화 대상

1. **파라미터 (Variables)**
   - 이동평균 기간
   - RSI 임계값
   - 손절/익절 비율
   - 거래량 필터 등

2. **목표 함수 (Objective)**
   - 총 수익률
   - Sharpe Ratio
   - 승률
   - MDD (최소화)

---

## Optuna 최적화

### Optuna란?

- 베이지안 최적화 프레임워크
- TPE (Tree-structured Parzen Estimator) 알고리즘
- 효율적인 하이퍼파라미터 탐색

### GUI에서 최적화 실행

#### Step 1: 최적화 설정

1. STOM 실행
2. `백테스트` 탭 → `최적화` 버튼 클릭
3. 최적화 설정:
   - **전략 선택**: 최적화할 전략
   - **기간 설정**: Train 기간 (예: 최근 3개월)
   - **Trial 수**: 100 (시도 횟수)
   - **Sampler**: TPE (기본) 또는 CmaEs

#### Step 2: 변수 범위 설정

```python
# 변수 범위 (JSON 형식)
{
    "ma_short": [3, 10],     # 3~10 사이
    "ma_long": [15, 30],     # 15~30 사이
    "rsi_low": [20, 40],     # 20~40 사이
    "rsi_high": [60, 80],    # 60~80 사이
    "profit_target": [1.0, 5.0],
    "stop_loss": [-3.0, -0.5]
}
```

#### Step 3: 목표 함수 선택

- **수익률 최대화** (기본)
- **Sharpe Ratio 최대화**
- **승률 최대화**
- **MDD 최소화**
- **복합 지표** (수익률 + MDD)

#### Step 4: 최적화 실행

`시작` 버튼 클릭 → Optuna가 자동으로 최적 파라미터 탐색

#### Step 5: 결과 확인

- **Best Trial**: 최적 파라미터
- **Best Value**: 최고 성능
- **파라미터 중요도**: 어떤 변수가 영향이 큰지
- **최적화 히스토리**: Trial별 성능 그래프

### 코드로 직접 최적화

**파일:** `backtester/optimiz.py`

```python
import optuna
from backtester.backengine_kiwoom_tick import BackEngineKiwoomTick

def objective(trial):
    """Optuna 목표 함수"""
    # 변수 범위 설정
    ma_short = trial.suggest_int('ma_short', 3, 10)
    ma_long = trial.suggest_int('ma_long', 15, 30)
    rsi_low = trial.suggest_int('rsi_low', 20, 40)
    rsi_high = trial.suggest_int('rsi_high', 60, 80)
    profit_target = trial.suggest_float('profit_target', 1.0, 5.0)
    stop_loss = trial.suggest_float('stop_loss', -3.0, -0.5)

    # 변수 딕셔너리
    vars = {
        'ma_short': ma_short,
        'ma_long': ma_long,
        'rsi_low': rsi_low,
        'rsi_high': rsi_high,
        'profit_target': profit_target,
        'stop_loss': stop_loss
    }

    # 백테스트 실행
    engine = BackEngineKiwoomTick(vars)
    result = engine.run()

    # 수익률 반환
    return result['총수익률']

# Study 생성
study = optuna.create_study(
    direction='maximize',  # 최대화
    sampler=optuna.samplers.TPESampler()
)

# 최적화 실행
study.optimize(objective, n_trials=100)

# 최적 파라미터
print('Best Trial:', study.best_trial.params)
print('Best Value:', study.best_value)
```

### Sampler 종류

#### 1. TPE (Tree-structured Parzen Estimator)

- **장점**: 빠르고 효율적
- **용도**: 일반적인 최적화
- **추천**: 기본 선택

```python
sampler = optuna.samplers.TPESampler()
```

#### 2. CmaEs (Covariance Matrix Adaptation Evolution Strategy)

- **장점**: 연속 변수에 강함
- **용도**: 변수가 많을 때

```python
sampler = optuna.samplers.CmaEsSampler()
```

#### 3. NSGA-II (다목적 최적화)

- **장점**: 여러 목표 동시 최적화
- **용도**: 수익률 + MDD 동시 최적화

```python
study = optuna.create_study(
    directions=['maximize', 'minimize'],  # 수익률 최대, MDD 최소
    sampler=optuna.samplers.NSGAIISampler()
)
```

---

## 유전 알고리즘

### 유전 알고리즘이란?

생물의 진화 과정을 모방한 최적화 알고리즘

1. **초기 집단** 생성
2. **선택** (적합도 높은 개체)
3. **교배** (우수 개체 조합)
4. **돌연변이**
5. 반복 → 최적해 도출

### GUI에서 실행

**파일:** `backtester/optimiz_genetic_algorithm.py`

1. `백테스트` 탭 → `유전 알고리즘` 버튼
2. 설정:
   - 집단 크기: 50
   - 세대 수: 100
   - 교배율: 0.7
   - 돌연변이율: 0.1
3. `시작` 버튼

### 코드 예시

```python
import random

def genetic_algorithm(population_size=50, generations=100):
    """유전 알고리즘 최적화"""
    # 1. 초기 집단 생성
    population = [random_individual() for _ in range(population_size)]

    for gen in range(generations):
        # 2. 적합도 평가
        fitness = [evaluate(individual) for individual in population]

        # 3. 선택 (상위 50%)
        population = select_top(population, fitness, 0.5)

        # 4. 교배
        offspring = crossover(population, crossover_rate=0.7)

        # 5. 돌연변이
        offspring = mutate(offspring, mutation_rate=0.1)

        # 6. 다음 세대
        population = population + offspring

    # 최적 개체 반환
    best = max(population, key=evaluate)
    return best

def random_individual():
    """무작위 개체 생성"""
    return {
        'ma_short': random.randint(3, 10),
        'ma_long': random.randint(15, 30),
        'rsi_low': random.randint(20, 40),
        # ...
    }

def evaluate(individual):
    """적합도 평가 (백테스트)"""
    result = backtest(individual)
    return result['총수익률']
```

---

## Walk-Forward Test

### Walk-Forward란?

**전진 분석**: 시간대별로 나눠서 최적화 및 검증

```
Period 1: [Train] [Test]
Period 2:         [Train] [Test]
Period 3:                 [Train] [Test]
```

### 장점

- **과최적화 방지**: 미래 데이터 사용 안 함
- **실전 근접**: 실제 트레이딩과 유사
- **안정성 검증**: 여러 기간에서 성능 확인

### GUI에서 실행

**파일:** `backtester/rolling_walk_forward_test.py`

1. `백테스트` 탭 → `Walk-Forward` 버튼
2. 설정:
   - Train 기간: 3개월
   - Test 기간: 1개월
   - 반복 횟수: 6 (총 6개월 * 4 = 24개월)
3. `시작` 버튼

### 코드 예시

```python
def walk_forward_test(total_period, train_period, test_period):
    """Walk-Forward Test"""
    results = []

    start = 0
    while start + train_period + test_period <= total_period:
        # Train 구간
        train_start = start
        train_end = start + train_period

        # Test 구간
        test_start = train_end
        test_end = test_start + test_period

        # 1. Train 구간에서 최적화
        train_data = get_data(train_start, train_end)
        best_params = optimize(train_data)

        # 2. Test 구간에서 검증
        test_data = get_data(test_start, test_end)
        test_result = backtest(test_data, best_params)

        results.append(test_result)

        # 다음 구간으로 이동
        start += test_period

    # 전체 결과 집계
    total_return = sum([r['수익률'] for r in results])
    return total_return, results

# 예시: 총 12개월, Train 3개월, Test 1개월
total_return, results = walk_forward_test(
    total_period=12,
    train_period=3,
    test_period=1
)
```

---

## 과최적화 방지

### 과최적화란?

과거 데이터에만 잘 맞고 미래에는 실패하는 현상

**증상:**
- 백테스트: 수익률 100%
- 실전: 수익률 -10%

### 방지 방법

#### 1. Train/Valid/Test 분리

```python
# 데이터 분리
train_data = data[:6개월]    # 최적화
valid_data = data[6:9개월]   # 검증
test_data = data[9:12개월]   # 최종 평가

# Train에서 최적화
best_params = optimize(train_data)

# Valid에서 검증
if validate(valid_data, best_params) > 기준:
    # Test에서 최종 평가
    final_result = backtest(test_data, best_params)
```

#### 2. Cross-Validation

```python
from sklearn.model_selection import KFold

kf = KFold(n_splits=5)
for train_idx, test_idx in kf.split(data):
    train_data = data[train_idx]
    test_data = data[test_idx]

    # 각 Fold에서 성능 평가
    result = backtest(train_data, test_data)
```

#### 3. 파라미터 개수 제한

- **최대 5개 이하**
- 변수가 많을수록 과최적화 위험

#### 4. 정규화 (Regularization)

```python
def objective(trial):
    # ... (변수 설정)

    # 백테스트
    result = backtest(vars)

    # 정규화: 복잡도 페널티
    complexity = len([v for v in vars.values() if v != 0])
    penalty = complexity * 0.01

    return result['수익률'] - penalty
```

#### 5. 아웃오브샘플 테스트

```python
# In-Sample (최적화)
in_sample = data[:9개월]
best_params = optimize(in_sample)

# Out-of-Sample (테스트)
out_sample = data[9:12개월]
oos_result = backtest(out_sample, best_params)

# OOS 성능이 IS의 70% 이상이면 OK
if oos_result / in_sample_result > 0.7:
    print('과최적화 아님')
```

#### 6. 심플리티 우선

- 단순한 전략이 강건함
- 이동평균 교차 > 복잡한 ML 모델

---

## 최적화 체크리스트

- [ ] 충분한 데이터 (최소 3개월 이상)
- [ ] Train/Valid/Test 분리
- [ ] 파라미터 개수 5개 이하
- [ ] Walk-Forward Test 수행
- [ ] Out-of-Sample 성능 확인
- [ ] 다양한 시장 상황 테스트
- [ ] 실전 전 모의투자 검증

---

## 다음 단계

최적화를 완료했다면:

1. **[05-백테스팅-시스템](./05-백테스팅-시스템.md)**: 백테스트 심화
2. **[10-전략-개발-가이드](./10-전략-개발-가이드.md)**: 전략 개선
3. **실전 투자 시작** (소액부터!)

---

**다음:** [12-문제해결-가이드](./12-문제해결-가이드.md)
