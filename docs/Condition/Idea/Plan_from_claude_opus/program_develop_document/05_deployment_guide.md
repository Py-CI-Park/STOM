# ë°°í¬ ë° ìš´ì˜ ê°€ì´ë“œ

## 1. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### 1.1 í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­

#### ìµœì†Œ ì‚¬ì–‘
- **CPU**: Intel i5 ë˜ëŠ” AMD Ryzen 5 ì´ìƒ
- **RAM**: 16GB
- **GPU**: NVIDIA GTX 1060 (6GB VRAM)
- **ì €ì¥ê³µê°„**: 50GB SSD

#### ê¶Œì¥ ì‚¬ì–‘
- **CPU**: Intel i7/i9 ë˜ëŠ” AMD Ryzen 7/9
- **RAM**: 32GB ì´ìƒ
- **GPU**: NVIDIA RTX 3070 ì´ìƒ (8GB+ VRAM)
- **ì €ì¥ê³µê°„**: 100GB+ NVMe SSD

### 1.2 ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­

```yaml
ìš´ì˜ì²´ì œ:
  - Windows 10/11 (64-bit)
  - Ubuntu 20.04/22.04 LTS
  
Python: 3.9 - 3.11

CUDA (GPU ì‚¬ìš©ì‹œ):
  - CUDA Toolkit 11.8+
  - cuDNN 8.6+
  - NVIDIA Driver 520+

ë°ì´í„°ë² ì´ìŠ¤:
  - SQLite 3.35+
```

## 2. í™˜ê²½ ì„¤ì •

### 2.1 Windows í™˜ê²½ ì„¤ì •

```powershell
# 1. Python ì„¤ì¹˜ í™•ì¸
python --version

# 2. CUDA ì„¤ì¹˜ (GPU ì‚¬ìš©ì‹œ)
# https://developer.nvidia.com/cuda-11-8-0-download-archive ì—ì„œ ë‹¤ìš´ë¡œë“œ

# 3. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
[System.Environment]::SetEnvironmentVariable("CUDA_PATH", "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8", "User")
[System.Environment]::SetEnvironmentVariable("PATH", "$env:PATH;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8\bin", "User")

# 4. Visual Studio Build Tools ì„¤ì¹˜ (C++ ì»´íŒŒì¼ëŸ¬)
# https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2022
```

### 2.2 Linux í™˜ê²½ ì„¤ì •

```bash
# 1. ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
sudo apt update && sudo apt upgrade -y

# 2. Python ë° í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
sudo apt install python3.9 python3.9-dev python3.9-venv
sudo apt install build-essential cmake git

# 3. CUDA ì„¤ì¹˜ (GPU ì‚¬ìš©ì‹œ)
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb
sudo dpkg -i cuda-keyring_1.0-1_all.deb
sudo apt-get update
sudo apt-get -y install cuda-11-8

# 4. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
echo 'export PATH=/usr/local/cuda-11.8/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc
```

## 3. í”„ë¡œì íŠ¸ ì„¤ì¹˜

### 3.1 í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±

```bash
# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir stom_ml_optimizer
cd stom_ml_optimizer

# ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
mkdir -p {core,data,models,training,backtesting,api,scripts,configs,logs,cache,reports}
mkdir -p data/{raw,processed,features}
mkdir -p models/{saved,checkpoints}
```

### 3.2 ê°€ìƒí™˜ê²½ ì„¤ì • ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv

# ê°€ìƒí™˜ê²½ í™œì„±í™”
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate

# pip ì—…ê·¸ë ˆì´ë“œ
pip install --upgrade pip setuptools wheel

# ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# GPU íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ì„ íƒì‚¬í•­)
pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 --index-url https://download.pytorch.org/whl/cu118
pip install cupy-cuda118
```

### 3.3 requirements.txt

```txt
# Core Dependencies
pandas==1.5.3
numpy==1.24.3
scikit-learn==1.3.0
scipy==1.11.1

# Machine Learning
lightgbm==4.0.0
xgboost==1.7.6
optuna==3.3.0
catboost==1.2

# Deep Learning (CPU version)
torch==2.0.1
torchvision==0.15.2

# Technical Analysis
ta-lib==0.4.27
pandas-ta==0.3.14b0

# Database
sqlalchemy==2.0.19
sqlite3

# API & Web
fastapi==0.100.0
uvicorn[standard]==0.23.1
pydantic==2.1.1
python-multipart==0.0.6

# Visualization
matplotlib==3.7.2
seaborn==0.12.2
plotly==5.15.0
streamlit==1.25.0

# Utilities
joblib==1.3.1
tqdm==4.65.0
python-dotenv==1.0.0
pyyaml==6.0.1
loguru==0.7.0

# Development
pytest==7.4.0
pytest-cov==4.1.0
black==23.7.0
flake8==6.0.0
mypy==1.4.1
```

### 3.4 TA-Lib ì„¤ì¹˜ (Windows)

```powershell
# TA-Lib ë°”ì´ë„ˆë¦¬ ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜
# https://www.lfd.uci.edu/~gohlke/pythonlibs/#ta-lib ì—ì„œ 
# Python ë²„ì „ì— ë§ëŠ” whl íŒŒì¼ ë‹¤ìš´ë¡œë“œ

# ì˜ˆ: Python 3.9 64-bit
pip install TA_Lib-0.4.27-cp39-cp39-win_amd64.whl
```

## 4. ì„¤ì • íŒŒì¼

### 4.1 í”„ë¡œì íŠ¸ ì„¤ì • (configs/config.yaml)

```yaml
# configs/config.yaml
project:
  name: "STOM ML Optimizer"
  version: "1.0.0"
  environment: "development"  # development, staging, production

database:
  path: "./data/stock_data.db"
  cache_size: 100000
  
data_pipeline:
  cache_dir: "./cache"
  use_cache: true
  max_workers: 4
  
models:
  save_dir: "./models/saved"
  checkpoint_dir: "./models/checkpoints"
  
  lightgbm:
    n_trials: 50
    cv_folds: 5
    early_stopping_rounds: 100
    
  lstm:
    batch_size: 64
    epochs: 100
    learning_rate: 0.001
    early_stopping_patience: 10
    
backtesting:
  initial_capital: 10000000
  max_positions: 10
  position_size: 0.1
  stop_loss: -3.0
  take_profit: 5.0
  trailing_stop: 2.0
  commission: 0.00015
  tax: 0.0023
  
api:
  host: "0.0.0.0"
  port: 8000
  workers: 4
  reload: false
  
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "./logs/app.log"
  max_size: "10MB"
  backup_count: 5
```

### 4.2 í™˜ê²½ë³€ìˆ˜ ì„¤ì • (.env)

```bash
# .env
# API Keys (if needed)
OPENAI_API_KEY=your_api_key_here
ALPHA_VANTAGE_KEY=your_api_key_here

# Database
DB_PATH=./data/stock_data.db

# Model Settings
MODEL_PATH=./models/saved
CHECKPOINT_PATH=./models/checkpoints

# Server Settings
API_HOST=0.0.0.0
API_PORT=8000

# Logging
LOG_LEVEL=INFO
LOG_FILE=./logs/app.log
```

## 5. ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

### 5.1 ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (run.py)

```python
#!/usr/bin/env python
# run.py
import os
import sys
import yaml
import argparse
import logging
from pathlib import Path
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

def setup_logging(config):
    """ë¡œê¹… ì„¤ì •"""
    logging.basicConfig(
        level=config['logging']['level'],
        format=config['logging']['format'],
        handlers=[
            logging.FileHandler(config['logging']['file']),
            logging.StreamHandler()
        ]
    )

def load_config(config_path='configs/config.yaml'):
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def main():
    parser = argparse.ArgumentParser(description='STOM ML Optimizer')
    parser.add_argument('command', choices=['train', 'backtest', 'predict', 'api', 'dashboard'])
    parser.add_argument('--config', default='configs/config.yaml', help='Config file path')
    parser.add_argument('--model', default='lightgbm', choices=['lightgbm', 'lstm', 'ensemble'])
    parser.add_argument('--stocks', nargs='+', default=['005930', '000660'])
    parser.add_argument('--start-date', default='20220101000000')
    parser.add_argument('--end-date', default='20231231235959')
    
    args = parser.parse_args()
    
    # ì„¤ì • ë¡œë“œ
    config = load_config(args.config)
    setup_logging(config)
    
    logger = logging.getLogger(__name__)
    logger.info(f"Starting {args.command} command...")
    
    if args.command == 'train':
        from scripts.train_full_pipeline import main as train_main
        train_main()
        
    elif args.command == 'backtest':
        from scripts.run_backtest import main as backtest_main
        backtest_main()
        
    elif args.command == 'predict':
        from api.predictor import predict_batch
        predictions = predict_batch(args.stocks, args.model)
        print(predictions)
        
    elif args.command == 'api':
        import uvicorn
        uvicorn.run(
            "api.server:app",
            host=config['api']['host'],
            port=config['api']['port'],
            workers=config['api']['workers'],
            reload=config['api']['reload']
        )
        
    elif args.command == 'dashboard':
        import streamlit.cli as stcli
        stcli.main(['run', 'dashboard/app.py'])

if __name__ == "__main__":
    main()
```

### 5.2 ë°°ì¹˜ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

#### Windows (run.bat)
```batch
@echo off
echo ========================================
echo STOM ML Optimizer
echo ========================================

:: ê°€ìƒí™˜ê²½ í™œì„±í™”
call venv\Scripts\activate

:: ëª…ë ¹ ì‹¤í–‰
if "%1"=="train" (
    echo Training models...
    python run.py train --model %2
) else if "%1"=="backtest" (
    echo Running backtest...
    python run.py backtest
) else if "%1"=="api" (
    echo Starting API server...
    python run.py api
) else if "%1"=="dashboard" (
    echo Starting dashboard...
    python run.py dashboard
) else (
    echo Usage: run.bat [train^|backtest^|api^|dashboard] [options]
)

pause
```

#### Linux (run.sh)
```bash
#!/bin/bash

echo "========================================"
echo "STOM ML Optimizer"
echo "========================================"

# ê°€ìƒí™˜ê²½ í™œì„±í™”
source venv/bin/activate

# ëª…ë ¹ ì‹¤í–‰
case "$1" in
    train)
        echo "Training models..."
        python run.py train --model ${2:-lightgbm}
        ;;
    backtest)
        echo "Running backtest..."
        python run.py backtest
        ;;
    api)
        echo "Starting API server..."
        python run.py api
        ;;
    dashboard)
        echo "Starting dashboard..."
        python run.py dashboard
        ;;
    *)
        echo "Usage: ./run.sh {train|backtest|api|dashboard} [options]"
        exit 1
esac
```

## 6. API ì„œë²„

### 6.1 FastAPI ì„œë²„ (api/server.py)

```python
# api/server.py
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Optional
import logging

app = FastAPI(title="STOM ML Optimizer API", version="1.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class PredictionRequest(BaseModel):
    stock_codes: List[str]
    model_type: str = "lightgbm"
    lookback_period: int = 100

class PredictionResponse(BaseModel):
    stock_code: str
    prediction: float
    signal: str
    confidence: float
    timestamp: str

@app.get("/")
def root():
    return {"message": "STOM ML Optimizer API", "status": "running"}

@app.get("/health")
def health_check():
    return {"status": "healthy"}

@app.post("/predict", response_model=List[PredictionResponse])
async def predict(request: PredictionRequest):
    """ì‹¤ì‹œê°„ ì˜ˆì¸¡ API"""
    try:
        from api.predictor import get_predictions
        
        predictions = get_predictions(
            request.stock_codes,
            request.model_type,
            request.lookback_period
        )
        
        return predictions
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/backtest")
async def run_backtest(background_tasks: BackgroundTasks):
    """ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ (ë¹„ë™ê¸°)"""
    background_tasks.add_task(execute_backtest)
    return {"message": "Backtest started", "status": "running"}

@app.get("/models")
def list_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡"""
    return {
        "models": ["lightgbm", "lstm", "xgboost", "ensemble"],
        "default": "lightgbm"
    }

@app.get("/performance")
def get_performance():
    """ìµœê·¼ ì„±ê³¼ ì§€í‘œ"""
    # ì‹¤ì œ êµ¬í˜„ í•„ìš”
    return {
        "total_return": 15.3,
        "sharpe_ratio": 1.8,
        "max_drawdown": -5.2,
        "win_rate": 0.62
    }

def execute_backtest():
    """ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ í•¨ìˆ˜"""
    import subprocess
    subprocess.run(["python", "scripts/run_backtest.py"])
```

## 7. ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

### 7.1 Streamlit ëŒ€ì‹œë³´ë“œ (dashboard/app.py)

```python
# dashboard/app.py
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import requests
import time

st.set_page_config(
    page_title="STOM ML Optimizer Dashboard",
    page_icon="ğŸ“ˆ",
    layout="wide"
)

st.title("ğŸ“ˆ STOM ML/DL ë°±í…ŒìŠ¤íŒ… ìµœì í™” ì‹œìŠ¤í…œ")

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ì„¤ì •")
    
    model_type = st.selectbox(
        "ëª¨ë¸ ì„ íƒ",
        ["lightgbm", "lstm", "xgboost", "ensemble"]
    )
    
    stock_codes = st.multiselect(
        "ì¢…ëª© ì„ íƒ",
        ["005930", "000660", "035720", "051910"],
        default=["005930", "000660"]
    )
    
    if st.button("ì˜ˆì¸¡ ì‹¤í–‰"):
        with st.spinner("ì˜ˆì¸¡ ì¤‘..."):
            # API í˜¸ì¶œ
            response = requests.post(
                "http://localhost:8000/predict",
                json={
                    "stock_codes": stock_codes,
                    "model_type": model_type
                }
            )
            if response.status_code == 200:
                st.success("ì˜ˆì¸¡ ì™„ë£Œ!")
            else:
                st.error("ì˜ˆì¸¡ ì‹¤íŒ¨")

# ë©”ì¸ ëŒ€ì‹œë³´ë“œ
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ì‹¤ì‹œê°„", "ğŸ“ˆ ë°±í…ŒìŠ¤íŒ…", "ğŸ¯ ëª¨ë¸ ì„±ëŠ¥", "âš™ï¸ ì„¤ì •"])

with tab1:
    st.header("ì‹¤ì‹œê°„ ì˜ˆì¸¡")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ì´ ìˆ˜ìµë¥ ", "15.3%", "2.1%")
    with col2:
        st.metric("ìƒ¤í”„ ë¹„ìœ¨", "1.85", "0.12")
    with col3:
        st.metric("ìµœëŒ€ ë‚™í­", "-5.2%", "-0.3%")
    with col4:
        st.metric("ìŠ¹ë¥ ", "62%", "3%")
    
    # ì‹¤ì‹œê°„ ì°¨íŠ¸
    st.subheader("í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜")
    
    # ë”ë¯¸ ë°ì´í„° (ì‹¤ì œë¡œëŠ” APIì—ì„œ ê°€ì ¸ì˜´)
    import numpy as np
    
    dates = pd.date_range(start='2023-01-01', periods=180, freq='D')
    portfolio_value = 10000000 * (1 + np.random.randn(180).cumsum() * 0.01)
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=dates,
        y=portfolio_value,
        mode='lines',
        name='Portfolio Value',
        line=dict(color='blue', width=2)
    ))
    
    fig.update_layout(
        height=400,
        xaxis_title="Date",
        yaxis_title="Portfolio Value (KRW)",
        hovermode='x unified'
    )
    
    st.plotly_chart(fig, use_container_width=True)

with tab2:
    st.header("ë°±í…ŒìŠ¤íŒ… ê²°ê³¼")
    
    # ë°±í…ŒìŠ¤íŒ… ì„¤ì •
    col1, col2, col3 = st.columns(3)
    
    with col1:
        start_date = st.date_input("ì‹œì‘ì¼", pd.to_datetime("2023-01-01"))
    with col2:
        end_date = st.date_input("ì¢…ë£Œì¼", pd.to_datetime("2023-12-31"))
    with col3:
        initial_capital = st.number_input("ì´ˆê¸° ìë³¸", value=10000000, step=1000000)
    
    if st.button("ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰"):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i in range(100):
            progress_bar.progress(i + 1)
            status_text.text(f'ì§„í–‰ë¥ : {i+1}%')
            time.sleep(0.01)
        
        st.success("ë°±í…ŒìŠ¤íŒ… ì™„ë£Œ!")
        
        # ê²°ê³¼ í‘œì‹œ
        results = {
            "ì´ ê±°ë˜": 245,
            "ìŠ¹ë¦¬": 152,
            "íŒ¨ë°°": 93,
            "ìŠ¹ë¥ ": "62%",
            "í‰ê·  ìˆ˜ìµ": "2.3%",
            "í‰ê·  ì†ì‹¤": "-1.5%",
            "Profit Factor": 1.85
        }
        
        st.json(results)

with tab3:
    st.header("ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
    
    # ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ
    models_performance = pd.DataFrame({
        'Model': ['LightGBM', 'LSTM', 'XGBoost', 'Ensemble'],
        'Accuracy': [0.65, 0.62, 0.64, 0.68],
        'Precision': [0.67, 0.63, 0.65, 0.69],
        'Recall': [0.63, 0.61, 0.63, 0.67],
        'F1 Score': [0.65, 0.62, 0.64, 0.68]
    })
    
    fig = go.Figure()
    
    for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score']:
        fig.add_trace(go.Bar(
            name=metric,
            x=models_performance['Model'],
            y=models_performance[metric]
        ))
    
    fig.update_layout(
        barmode='group',
        height=400,
        title="ëª¨ë¸ë³„ ì„±ëŠ¥ ì§€í‘œ"
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # íŠ¹ì„± ì¤‘ìš”ë„
    st.subheader("íŠ¹ì„± ì¤‘ìš”ë„ (Top 10)")
    
    feature_importance = pd.DataFrame({
        'Feature': ['ì´ˆë‹¹ê±°ë˜ëŒ€ê¸ˆ', 'ì²´ê²°ê°•ë„', 'ë“±ë½ìœ¨', 'ë§¤ë„ì´ì”ëŸ‰', 'ë§¤ìˆ˜ì´ì”ëŸ‰',
                   'RSI', 'MACD', 'ì´ë™í‰ê· ', 'ë³¼ë¦°ì €ë°´ë“œ', 'ê±°ë˜ëŸ‰'],
        'Importance': [0.15, 0.12, 0.10, 0.09, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03]
    })
    
    fig = go.Figure(go.Bar(
        x=feature_importance['Importance'],
        y=feature_importance['Feature'],
        orientation='h'
    ))
    
    fig.update_layout(
        height=400,
        title="íŠ¹ì„± ì¤‘ìš”ë„",
        xaxis_title="Importance",
        yaxis_title="Feature"
    )
    
    st.plotly_chart(fig, use_container_width=True)

with tab4:
    st.header("ì‹œìŠ¤í…œ ì„¤ì •")
    
    st.subheader("ë°ì´í„°ë² ì´ìŠ¤")
    db_path = st.text_input("DB ê²½ë¡œ", value="./data/stock_data.db")
    
    st.subheader("ëª¨ë¸ ì„¤ì •")
    col1, col2 = st.columns(2)
    
    with col1:
        epochs = st.slider("Epochs", 10, 200, 100)
        batch_size = st.slider("Batch Size", 16, 128, 64)
    
    with col2:
        learning_rate = st.slider("Learning Rate", 0.0001, 0.1, 0.001, format="%.4f")
        dropout = st.slider("Dropout", 0.0, 0.5, 0.2)
    
    st.subheader("ë°±í…ŒìŠ¤íŒ… ì„¤ì •")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        stop_loss = st.slider("Stop Loss (%)", -10.0, -1.0, -3.0)
    with col2:
        take_profit = st.slider("Take Profit (%)", 1.0, 20.0, 5.0)
    with col3:
        position_size = st.slider("Position Size (%)", 5, 30, 10)
    
    if st.button("ì„¤ì • ì €ì¥"):
        st.success("ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
```

## 8. ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§

### 8.1 ë¡œê·¸ ëª¨ë‹ˆí„°ë§

```python
# monitoring/log_monitor.py
import logging
from logging.handlers import RotatingFileHandler, SMTPHandler
import sys

def setup_monitoring():
    """ëª¨ë‹ˆí„°ë§ ì„¤ì •"""
    
    # ë¡œê±° ìƒì„±
    logger = logging.getLogger('stom_ml')
    logger.setLevel(logging.INFO)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ (ë¡œí…Œì´ì…˜)
    file_handler = RotatingFileHandler(
        'logs/app.log',
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5
    )
    file_handler.setFormatter(
        logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    )
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(
        logging.Formatter('%(levelname)s - %(message)s')
    )
    
    # ì´ë©”ì¼ ì•Œë¦¼ (ì—ëŸ¬ ë°œìƒì‹œ)
    if False:  # í•„ìš”ì‹œ í™œì„±í™”
        mail_handler = SMTPHandler(
            mailhost='smtp.gmail.com',
            fromaddr='alert@stom.com',
            toaddrs=['admin@stom.com'],
            subject='STOM ML System Error',
            credentials=('username', 'password'),
            secure=()
        )
        mail_handler.setLevel(logging.ERROR)
        logger.addHandler(mail_handler)
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger
```

### 8.2 ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```python
# monitoring/performance_monitor.py
import psutil
import GPUtil
import time
from datetime import datetime

class SystemMonitor:
    """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§"""
    
    @staticmethod
    def get_system_info():
        """ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘"""
        
        # CPU ì‚¬ìš©ë¥ 
        cpu_percent = psutil.cpu_percent(interval=1)
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
        memory = psutil.virtual_memory()
        memory_percent = memory.percent
        memory_used_gb = memory.used / (1024**3)
        
        # ë””ìŠ¤í¬ ì‚¬ìš©ë¥ 
        disk = psutil.disk_usage('/')
        disk_percent = disk.percent
        
        # GPU ì •ë³´ (NVIDIA)
        gpu_info = []
        try:
            gpus = GPUtil.getGPUs()
            for gpu in gpus:
                gpu_info.append({
                    'name': gpu.name,
                    'load': f"{gpu.load*100:.1f}%",
                    'memory': f"{gpu.memoryUsed}/{gpu.memoryTotal}MB",
                    'temp': f"{gpu.temperature}Â°C"
                })
        except:
            gpu_info = None
        
        return {
            'timestamp': datetime.now().isoformat(),
            'cpu_percent': cpu_percent,
            'memory_percent': memory_percent,
            'memory_used_gb': memory_used_gb,
            'disk_percent': disk_percent,
            'gpu_info': gpu_info
        }
    
    @staticmethod
    def monitor_loop(interval=60):
        """ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while True:
            info = SystemMonitor.get_system_info()
            
            # ë¡œê·¸ ê¸°ë¡
            with open('logs/system_monitor.log', 'a') as f:
                f.write(f"{info}\n")
            
            # ê²½ê³  í™•ì¸
            if info['cpu_percent'] > 90:
                print(f"âš ï¸ CPU ì‚¬ìš©ë¥  ë†’ìŒ: {info['cpu_percent']}%")
            
            if info['memory_percent'] > 90:
                print(f"âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ: {info['memory_percent']}%")
            
            time.sleep(interval)
```

## 9. ìš´ì˜ ë° ìœ ì§€ë³´ìˆ˜

### 9.1 ì¼ì¼ ì ê²€ ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/daily_check.py
#!/usr/bin/env python

import os
import sys
import sqlite3
from datetime import datetime, timedelta
import logging

def check_database():
    """ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸"""
    try:
        conn = sqlite3.connect('./data/stock_data.db')
        cursor = conn.cursor()
        
        # í…Œì´ë¸” ìˆ˜ í™•ì¸
        cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='table'")
        table_count = cursor.fetchone()[0]
        
        # ìµœì‹  ë°ì´í„° í™•ì¸
        cursor.execute("SELECT MAX(datetime('now')) FROM '005930' LIMIT 1")
        latest_data = cursor.fetchone()[0]
        
        conn.close()
        
        return {
            'status': 'OK',
            'tables': table_count,
            'latest_data': latest_data
        }
    except Exception as e:
        return {'status': 'ERROR', 'error': str(e)}

def check_models():
    """ëª¨ë¸ ìƒíƒœ í™•ì¸"""
    model_files = [
        './models/saved/lightgbm_model.pkl',
        './models/saved/lstm_model.pth',
        './models/saved/ensemble_model.pkl'
    ]
    
    results = {}
    for model_file in model_files:
        if os.path.exists(model_file):
            size = os.path.getsize(model_file) / (1024*1024)  # MB
            modified = datetime.fromtimestamp(os.path.getmtime(model_file))
            results[model_file] = {
                'exists': True,
                'size_mb': f"{size:.2f}",
                'modified': modified.isoformat()
            }
        else:
            results[model_file] = {'exists': False}
    
    return results

def check_disk_space():
    """ë””ìŠ¤í¬ ê³µê°„ í™•ì¸"""
    import shutil
    
    total, used, free = shutil.disk_usage("/")
    
    return {
        'total_gb': total // (2**30),
        'used_gb': used // (2**30),
        'free_gb': free // (2**30),
        'used_percent': (used / total) * 100
    }

def main():
    print("=" * 60)
    print("ì¼ì¼ ì‹œìŠ¤í…œ ì ê²€")
    print("=" * 60)
    print(f"ì ê²€ ì‹œê°„: {datetime.now()}")
    print()
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì ê²€
    print("1. ë°ì´í„°ë² ì´ìŠ¤ ì ê²€")
    db_status = check_database()
    for key, value in db_status.items():
        print(f"  - {key}: {value}")
    print()
    
    # ëª¨ë¸ ì ê²€
    print("2. ëª¨ë¸ íŒŒì¼ ì ê²€")
    model_status = check_models()
    for model, status in model_status.items():
        print(f"  - {model}:")
        for key, value in status.items():
            print(f"    {key}: {value}")
    print()
    
    # ë””ìŠ¤í¬ ê³µê°„ ì ê²€
    print("3. ë””ìŠ¤í¬ ê³µê°„")
    disk_status = check_disk_space()
    for key, value in disk_status.items():
        print(f"  - {key}: {value}")
    
    # ê²½ê³  í™•ì¸
    if disk_status['used_percent'] > 80:
        print("\nâš ï¸ ê²½ê³ : ë””ìŠ¤í¬ ì‚¬ìš©ë¥ ì´ 80%ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤!")
    
    print("\nì ê²€ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
```

### 9.2 ë°±ì—… ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/backup.sh

BACKUP_DIR="/backup/stom_ml"
DATE=$(date +%Y%m%d_%H%M%S)

echo "Starting backup at $DATE"

# ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
mkdir -p $BACKUP_DIR/db
cp ./data/stock_data.db $BACKUP_DIR/db/stock_data_$DATE.db

# ëª¨ë¸ ë°±ì—…
mkdir -p $BACKUP_DIR/models
cp -r ./models/saved/* $BACKUP_DIR/models/

# ì„¤ì • íŒŒì¼ ë°±ì—…
mkdir -p $BACKUP_DIR/configs
cp -r ./configs/* $BACKUP_DIR/configs/

# ì••ì¶•
tar -czf $BACKUP_DIR/backup_$DATE.tar.gz $BACKUP_DIR/db $BACKUP_DIR/models $BACKUP_DIR/configs

# 30ì¼ ì´ìƒ ëœ ë°±ì—… ì‚­ì œ
find $BACKUP_DIR -name "backup_*.tar.gz" -mtime +30 -delete

echo "Backup completed"
```

## 10. ë¬¸ì œ í•´ê²°

### 10.1 ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œ

#### CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# GPU ë©”ëª¨ë¦¬ ì •ë¦¬
import torch
torch.cuda.empty_cache()

# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
batch_size = 32  # 64ì—ì„œ ê°ì†Œ
```

#### TA-Lib ì„¤ì¹˜ ì˜¤ë¥˜
```bash
# Windows: Visual C++ 14.0 í•„ìš”
# https://visualstudio.microsoft.com/downloads/

# Linux
sudo apt-get install ta-lib
pip install ta-lib
```

#### ë°ì´í„°ë² ì´ìŠ¤ ë½
```python
# íƒ€ì„ì•„ì›ƒ ì¦ê°€
conn = sqlite3.connect('stock_data.db', timeout=30.0)
```

### 10.2 ì„±ëŠ¥ ìµœì í™” íŒ

1. **ë°ì´í„° ìºì‹± í™œìš©**
2. **ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸° ì¡°ì •**
3. **ë¶ˆí•„ìš”í•œ íŠ¹ì„± ì œê±°**
4. **ëª¨ë¸ ê²½ëŸ‰í™” (pruning, quantization)**
5. **ë¹„ë™ê¸° ì²˜ë¦¬ í™œìš©**

## 11. ê²°ë¡ 

ì´ ê°€ì´ë“œë¥¼ í†µí•´ STOM ML/DL ë°±í…ŒìŠ¤íŒ… ìµœì í™” ì‹œìŠ¤í…œì„ ì„±ê³µì ìœ¼ë¡œ ë°°í¬í•˜ê³  ìš´ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ê³¼ ê°œì„ ì„ í†µí•´ ì‹œìŠ¤í…œ ì„±ëŠ¥ì„ ìµœì í™”í•˜ì„¸ìš”.
