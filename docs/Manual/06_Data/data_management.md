# 06. ë°ì´í„° ê´€ë¦¬

## ğŸ“Š ë°ì´í„° ê´€ë¦¬ ê°œìš”

STOM ì‹œìŠ¤í…œì€ **ê³ ì„±ëŠ¥ ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬**ë¥¼ ìœ„í•œ ë‹¤ì¸µ ë°ì´í„° ì•„í‚¤í…ì²˜ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤. ì£¼ì‹ê³¼ ì•”í˜¸í™”í ì‹œì¥ì˜ í‹± ë°ì´í„°ë¶€í„° ë¶„ë´‰ ë°ì´í„°ê¹Œì§€ ë‹¤ì–‘í•œ ì‹œê°„ í”„ë ˆì„ì˜ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜ì§‘, ì €ì¥, ì²˜ë¦¬í•©ë‹ˆë‹¤.

### ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
```
ğŸ“¡ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì‹ 
    â†“
ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ë° ê²€ì¦
    â†“
ğŸ’¾ ë©”ëª¨ë¦¬ ë²„í¼ë§ (ê³ ì† ì²˜ë¦¬)
    â†“
ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ (ì˜êµ¬ ë³´ê´€)
    â†“
ğŸ“ˆ ì°¨íŠ¸ ë° ë¶„ì„ ì‹œìŠ¤í…œ ê³µê¸‰
```

---

## ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì•„í‚¤í…ì²˜

### SQLite ê¸°ë°˜ ë°ì´í„° ì €ì¥ì†Œ

#### 1. ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° (`utility/setting.py:31-49`)

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
# ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ ì„¤ì •
OPENAPI_PATH       = 'C:/OpenAPI'
ICON_PATH          = './icon'
LOGIN_PATH         = './stock/login_kiwoom'
GRAPH_PATH         = './backtester/graph'
BACK_TEMP          = './backtester/temp'
DB_PATH            = './_database'
DB_SETTING         = './_database/setting.db'
DB_BACKTEST        = './_database/backtest.db'
DB_TRADELIST       = './_database/tradelist.db'
DB_STOCK_TICK      = './_database/stock_tick.db'
DB_STOCK_MIN       = './_database/stock_min.db'
DB_STOCK_BACK_TICK = './_database/stock_tick_back.db'
DB_STOCK_BACK_MIN  = './_database/stock_min_back.db'
DB_COIN_TICK       = './_database/coin_tick.db'
DB_COIN_MIN        = './_database/coin_min.db'
DB_COIN_BACK_TICK  = './_database/coin_tick_back.db'
DB_COIN_BACK_MIN   = './_database/coin_min_back.db'
DB_STRATEGY        = './_database/strategy.db'
DB_OPTUNA          = 'sqlite:///./_database/optuna.db'
```

**ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ëª©ë¡:**
- **ì„¤ì • DB**: `setting.db` - ì‹œìŠ¤í…œ ì„¤ì • ë° ì•”í˜¸í™”ëœ ê³„ì • ì •ë³´
- **ê±°ë˜ DB**: `tradelist.db` - ì²´ê²°, ì”ê³ , ê±°ë˜ ë‚´ì—­
- **ì „ëµ DB**: `strategy.db` - ë§¤ë§¤ ì „ëµ ì½”ë“œ ë° ì¡°ê±´ì‹
- **ë°±í…ŒìŠ¤íŠ¸ DB**: `backtest.db` - ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ë°ì´í„°
- **ì£¼ì‹ ë°ì´í„° DB**: `stock_tick.db`, `stock_min.db` - ì‹¤ì‹œê°„ ì£¼ì‹ ì‹œì¥ ë°ì´í„°
- **ì•”í˜¸í™”í ë°ì´í„° DB**: `coin_tick.db`, `coin_min.db` - ì‹¤ì‹œê°„ ì•”í˜¸í™”í ì‹œì¥ ë°ì´í„°
- **ë°±í…ŒìŠ¤íŠ¸ìš© DB**: `stock_tick_back.db`, `stock_min_back.db`, `coin_tick_back.db`, `coin_min_back.db`
- **ìµœì í™” DB**: `optuna.db` - Optuna ìµœì í™” ê²°ê³¼

#### 2. í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì„¤ê³„ (`utility/database_check.py`)

##### ì„¤ì • DB í…Œì´ë¸” (`setting.db`)

**main í…Œì´ë¸”** - ì‹œìŠ¤í…œ ì£¼ìš” ì„¤ì •

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
columns = [
    'index', 'ì¦ê¶Œì‚¬', 'ì£¼ì‹ë¦¬ì‹œë²„', 'ì£¼ì‹íŠ¸ë ˆì´ë”', 'ì£¼ì‹ë°ì´í„°ì €ì¥', 'ê±°ë˜ì†Œ',
    'ì½”ì¸ë¦¬ì‹œë²„', 'ì½”ì¸íŠ¸ë ˆì´ë”', 'ì½”ì¸ë°ì´í„°ì €ì¥', 'ë°”ì´ë‚¸ìŠ¤ì„ ë¬¼ê³ ì •ë ˆë²„ë¦¬ì§€',
    'ë°”ì´ë‚¸ìŠ¤ì„ ë¬¼ê³ ì •ë ˆë²„ë¦¬ì§€ê°’', 'ë°”ì´ë‚¸ìŠ¤ì„ ë¬¼ë³€ë™ë ˆë²„ë¦¬ì§€ê°’', 'ë°”ì´ë‚¸ìŠ¤ì„ ë¬¼ë§ˆì§„íƒ€ì…',
    'ë°”ì´ë‚¸ìŠ¤ì„ ë¬¼í¬ì§€ì…˜', 'ë²„ì „ì—…', 'ë¦¬ì‹œë²„ê³µìœ '
]
```

**sacc í…Œì´ë¸”** - ì£¼ì‹ ê³„ì • ì •ë³´ (ì•”í˜¸í™”ë¨)

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
columns = ["index", "ì•„ì´ë””", "ë¹„ë°€ë²ˆí˜¸", "ì¸ì¦ì„œë¹„ë°€ë²ˆí˜¸", "ê³„ì¢Œë¹„ë°€ë²ˆí˜¸"]
# 1~8ë²ˆê¹Œì§€ ìµœëŒ€ 8ê°œ ê³„ì • ì§€ì›
```

**cacc í…Œì´ë¸”** - ì•”í˜¸í™”í API í‚¤ (ì•”í˜¸í™”ë¨)

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
columns = ["index", "Access_key", "Secret_key"]
# Upbit, Binance ë“± ê±°ë˜ì†Œ API í‚¤ ì €ì¥
```

**stock í…Œì´ë¸”** - ì£¼ì‹ ê±°ë˜ ì„¤ì •

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
columns = [
    "index", "ì£¼ì‹ëª¨ì˜íˆ¬ì", "ì£¼ì‹ì•Œë¦¼ì†Œë¦¬", "ì£¼ì‹ë§¤ìˆ˜ì „ëµ", "ì£¼ì‹ë§¤ë„ì „ëµ",
    "ì£¼ì‹íƒ€ì„í”„ë ˆì„", "ì£¼ì‹í‰ê· ê°’ê³„ì‚°í‹±ìˆ˜", "ì£¼ì‹ìµœëŒ€ë§¤ìˆ˜ì¢…ëª©ìˆ˜", "ì£¼ì‹ì „ëµì¢…ë£Œì‹œê°„",
    "ì£¼ì‹ì”ê³ ì²­ì‚°", "ì£¼ì‹í”„ë¡œì„¸ìŠ¤ì¢…ë£Œ", "ì£¼ì‹ì»´í“¨í„°ì¢…ë£Œ", "ì£¼ì‹íˆ¬ìê¸ˆê³ ì •", "ì£¼ì‹íˆ¬ìê¸ˆ",
    "ì£¼ì‹ì†ì‹¤ì¤‘ì§€", "ì£¼ì‹ì†ì‹¤ì¤‘ì§€ìˆ˜ìµë¥ ", "ì£¼ì‹ìˆ˜ìµì¤‘ì§€", "ì£¼ì‹ìˆ˜ìµì¤‘ì§€ìˆ˜ìµë¥ ", "ì£¼ì‹ê²½ê³¼í‹±ìˆ˜ì„¤ì •"
]
```

**coin í…Œì´ë¸”** - ì•”í˜¸í™”í ê±°ë˜ ì„¤ì •

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
columns = [
    "index", "ì½”ì¸ëª¨ì˜íˆ¬ì", "ì½”ì¸ì•Œë¦¼ì†Œë¦¬", "ì½”ì¸ë§¤ìˆ˜ì „ëµ", "ì½”ì¸ë§¤ë„ì „ëµ",
    "ì½”ì¸íƒ€ì„í”„ë ˆì„", "ì½”ì¸í‰ê· ê°’ê³„ì‚°í‹±ìˆ˜", "ì½”ì¸ìµœëŒ€ë§¤ìˆ˜ì¢…ëª©ìˆ˜", "ì½”ì¸ì „ëµì¢…ë£Œì‹œê°„",
    "ì½”ì¸ì”ê³ ì²­ì‚°", "ì½”ì¸í”„ë¡œì„¸ìŠ¤ì¢…ë£Œ", "ì½”ì¸ì»´í“¨í„°ì¢…ë£Œ", "ì½”ì¸íˆ¬ìê¸ˆê³ ì •", "ì½”ì¸íˆ¬ìê¸ˆ",
    "ì½”ì¸ì†ì‹¤ì¤‘ì§€", "ì½”ì¸ì†ì‹¤ì¤‘ì§€ìˆ˜ìµë¥ ", "ì½”ì¸ìˆ˜ìµì¤‘ì§€", "ì½”ì¸ìˆ˜ìµì¤‘ì§€ìˆ˜ìµë¥ ", "ì½”ì¸ê²½ê³¼í‹±ìˆ˜ì„¤ì •"
]
```

**stockbuyorder/stocksellorder í…Œì´ë¸”** - ì£¼ì‹ ë§¤ìˆ˜/ë§¤ë„ ì£¼ë¬¸ ì„¤ì •

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
# ë§¤ìˆ˜ ì£¼ë¬¸ ì„¤ì •: ì£¼ë¬¸êµ¬ë¶„, ë¶„í• íšŸìˆ˜, ë¶„í• ë°©ë²•, ì·¨ì†Œì¡°ê±´, ê¸ˆì§€ì¡°ê±´ ë“±
# ë§¤ë„ ì£¼ë¬¸ ì„¤ì •: ì†ì ˆìˆ˜ìµë¥ , ìˆ˜ìµê¸ˆ ì„¤ì •, ì·¨ì†Œì¡°ê±´ ë“±
```

##### ê±°ë˜ DB í…Œì´ë¸” (`tradelist.db`) (`utility/database_check.py:244-318`)

**s_chegeollist / c_chegeollist** - ì£¼ì‹/ì½”ì¸ ì²´ê²° ë‚´ì—­

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
query = 'CREATE TABLE "s_chegeollist" (
    "index" TEXT, "ì¢…ëª©ëª…" TEXT, "ì£¼ë¬¸êµ¬ë¶„" TEXT, "ì£¼ë¬¸ìˆ˜ëŸ‰" INTEGER,
    "ì²´ê²°ìˆ˜ëŸ‰" INTEGER, "ë¯¸ì²´ê²°ìˆ˜ëŸ‰" INTEGER, "ì²´ê²°ê°€" INTEGER,
    "ì²´ê²°ì‹œê°„" TEXT, "ì£¼ë¬¸ê°€ê²©" INTEGER, "ì£¼ë¬¸ë²ˆí˜¸" TEXT
)'
```

**s_jangolist / c_jangolist** - ì£¼ì‹/ì½”ì¸ ì”ê³  ë‚´ì—­

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
query = 'CREATE TABLE "s_jangolist" (
    "index" TEXT, "ì¢…ëª©ëª…" TEXT, "ë§¤ì…ê°€" INTEGER, "í˜„ì¬ê°€" INTEGER,
    "ìˆ˜ìµë¥ " REAL, "í‰ê°€ì†ìµ" INTEGER, "ë§¤ì…ê¸ˆì•¡" INTEGER, "í‰ê°€ê¸ˆì•¡" INTEGER,
    "ë³´ìœ ìˆ˜ëŸ‰" INTEGER, "ë¶„í• ë§¤ìˆ˜íšŸìˆ˜" INTEGER, "ë¶„í• ë§¤ë„íšŸìˆ˜" INTEGER, "ë§¤ìˆ˜ì‹œê°„" TEXT
)'
```

**c_jangolist_future** - ì½”ì¸ ì„ ë¬¼ ì”ê³  (ë°”ì´ë‚¸ìŠ¤)

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
query = 'CREATE TABLE "c_jangolist_future" (
    "index" TEXT, "ì¢…ëª©ëª…" TEXT, "í¬ì§€ì…˜" TEXT, "ë§¤ì…ê°€" REAL, "í˜„ì¬ê°€" REAL,
    "ìˆ˜ìµë¥ " REAL, "í‰ê°€ì†ìµ" INTEGER, "ë§¤ì…ê¸ˆì•¡" INTEGER, "í‰ê°€ê¸ˆì•¡" INTEGER,
    "ë³´ìœ ìˆ˜ëŸ‰" REAL, "ë ˆë²„ë¦¬ì§€" INTEGER, "ë¶„í• ë§¤ìˆ˜íšŸìˆ˜" INTEGER,
    "ë¶„í• ë§¤ë„íšŸìˆ˜" INTEGER, "ë§¤ìˆ˜ì‹œê°„" TEXT
)'
```

**s_tradelist / c_tradelist** - ì£¼ì‹/ì½”ì¸ ê±°ë˜ ë‚´ì—­

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
query = 'CREATE TABLE "s_tradelist" (
    "index" TEXT, "ì¢…ëª©ëª…" TEXT, "ë§¤ìˆ˜ê¸ˆì•¡" INTEGER, "ë§¤ë„ê¸ˆì•¡" INTEGER,
    "ì£¼ë¬¸ìˆ˜ëŸ‰" INTEGER, "ìˆ˜ìµë¥ " REAL, "ìˆ˜ìµê¸ˆ" INTEGER, "ì²´ê²°ì‹œê°„" TEXT
)'
```

**s_totaltradelist / c_totaltradelist** - ì´ ê±°ë˜ ì§‘ê³„

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
query = 'CREATE TABLE "s_totaltradelist" (
    "index" TEXT, "ì´ë§¤ìˆ˜ê¸ˆì•¡" INTEGER, "ì´ë§¤ë„ê¸ˆì•¡" INTEGER,
    "ì´ìˆ˜ìµê¸ˆì•¡" INTEGER, "ì´ì†ì‹¤ê¸ˆì•¡" INTEGER, "ìˆ˜ìµë¥ " REAL, "ìˆ˜ìµê¸ˆí•©ê³„" INTEGER
)'
```

##### ì „ëµ DB í…Œì´ë¸” (`strategy.db`) (`utility/database_check.py:166-241`)

**stockbuy/stocksell, coinbuy/coinsell** - ë§¤ë§¤ ì „ëµ ì½”ë“œ

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
cur.execute('CREATE TABLE "stockbuy" ( "index" TEXT, "ì „ëµì½”ë“œ" TEXT )')
cur.execute('CREATE INDEX "ix_stockbuy_index" ON "stockbuy" ("index")')
```

**stockbuyconds/stocksellconds** - ë§¤ë§¤ ì¡°ê±´ì‹

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
cur.execute('CREATE TABLE "stockbuyconds" ( "index" TEXT, "ì „ëµì½”ë“œ" TEXT )')
```

**stockvars/coinvars** - ì „ëµ ë³€ìˆ˜

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
cur.execute('CREATE TABLE "stockvars" ( "index" TEXT, "ì „ëµì½”ë“œ" TEXT )')
```

**stockoptibuy/stockoptisell** - ìµœì í™”ìš© ì „ëµ

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
query = 'CREATE TABLE "stockoptibuy" ( "index" TEXT, "ì „ëµì½”ë“œ" TEXT, "ë³€ìˆ˜ê°’" TEXT )'
```

##### ì‹œì¥ ë°ì´í„° DB í…Œì´ë¸” (ë™ì  ìƒì„±)

**moneytop í…Œì´ë¸”** - ê±°ë˜ëŒ€ê¸ˆ ìˆœìœ„ (ëª¨ë“  tick/min DBì— ì¡´ì¬)

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
# index: ì‹œê°„ (YYYYMMDDHHMMSS)
# ê±°ë˜ëŒ€ê¸ˆìˆœìœ„: ì„¸ë¯¸ì½œë¡ ìœ¼ë¡œ êµ¬ë¶„ëœ ì¢…ëª©ì½”ë“œ/ë§ˆì¼“ ë¦¬ìŠ¤íŠ¸
```

**[ì¢…ëª©ì½”ë“œ/ë§ˆì¼“] í…Œì´ë¸”** - ê°œë³„ ì¢…ëª© ë°ì´í„° (ë™ì  ìƒì„±)

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
# ì£¼ì‹ í‹±: index, í˜„ì¬ê°€, ì‹œê°€, ê³ ê°€, ì €ê°€, ë“±ë½ë¥ , ë‹¹ì¼ê±°ë˜ëŒ€ê¸ˆ,
#          ì²´ê²°ê°•ë„, í˜¸ê°€ì´ì”ëŸ‰, ë§¤ìˆ˜í˜¸ê°€1~10, ë§¤ë„í˜¸ê°€1~10, ë§¤ìˆ˜ì”ëŸ‰1~10, ë§¤ë„ì”ëŸ‰1~10
# ì½”ì¸ í‹±: index, í˜„ì¬ê°€, ì‹œê°€, ê³ ê°€, ì €ê°€, ë“±ë½ë¥ , ë‹¹ì¼ê±°ë˜ëŒ€ê¸ˆ,
#          ëˆ„ì ë§¤ìˆ˜ëŸ‰, ëˆ„ì ë§¤ë„ëŸ‰, ë§¤ìˆ˜í˜¸ê°€1~10, ë§¤ë„í˜¸ê°€1~10, ë§¤ìˆ˜ì”ëŸ‰1~10, ë§¤ë„ì”ëŸ‰1~10
# ë¶„ë´‰: index, ì‹œê°€, ê³ ê°€, ì €ê°€, ì¢…ê°€, ê±°ë˜ëŸ‰, ê±°ë˜ëŒ€ê¸ˆ
```

### ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê´€ë¦¬

#### 1. Query í”„ë¡œì„¸ìŠ¤ (`utility/query.py:12-89`)

STOMì€ ë³„ë„ì˜ í”„ë¡œì„¸ìŠ¤ë¡œ **Query** í´ë˜ìŠ¤ë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
class Query:
    def __init__(self, qlist):
        """
        ë©€í‹°í”„ë¡œì„¸ìŠ¤ í™˜ê²½ì—ì„œ DB ì‘ì—…ì„ ì „ë‹´í•˜ëŠ” Query í”„ë¡œì„¸ìŠ¤
        - windowQ, queryQ ë“±ì˜ íë¥¼ í†µí•´ ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ì™€ í†µì‹ 
        """
        self.windowQ  = qlist[0]
        self.queryQ   = qlist[2]

        # 3ê°œì˜ ì£¼ìš” ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        self.con1     = sqlite3.connect(DB_SETTING)     # ì„¤ì • DB
        self.cur1     = self.con1.cursor()
        self.con2     = sqlite3.connect(DB_TRADELIST)   # ê±°ë˜ DB
        self.cur2     = self.con2.cursor()
        self.con3     = sqlite3.connect(DB_STRATEGY)    # ì „ëµ DB
        self.cur3     = self.con3.cursor()

        self.dict_set = DICT_SET
        self.Start()

    def __del__(self):
        """í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹œ ëª¨ë“  DB ì—°ê²° ì¢…ë£Œ"""
        self.con1.close()
        self.con2.close()
        self.con3.close()

    def Start(self):
        """ë©”ì¸ ë£¨í”„: íì—ì„œ ì¿¼ë¦¬ ìš”ì²­ì„ ë°›ì•„ ì²˜ë¦¬"""
        while True:
            query = self.queryQ.get()

            if query[0] == 'ì„¤ì •ë³€ê²½':
                self.dict_set = query[1]

            elif query[0] == 'ì„¤ì •ë””ë¹„':
                try:
                    if len(query) == 2:
                        # ì§ì ‘ SQL ì‹¤í–‰
                        self.cur1.execute(query[1])
                        self.con1.commit()
                    elif len(query) == 4:
                        # DataFrameì„ SQL í…Œì´ë¸”ë¡œ ì €ì¥
                        # query[1]: DataFrame, query[2]: í…Œì´ë¸”ëª…, query[3]: 'append'/'replace'
                        query[1].to_sql(query[2], self.con1, if_exists=query[3], chunksize=1000)
                except Exception as e:
                    self.windowQ.put((ui_num['Së¡œê·¸í…ìŠ¤íŠ¸'], f'ì˜¤ë¥˜ - Query ì„¤ì •ë””ë¹„ {e}'))

            elif query[0] == 'ê±°ë˜ë””ë¹„':
                try:
                    if len(query) == 2:
                        self.cur2.execute(query[1])
                        self.con2.commit()
                    elif len(query) == 4:
                        query[1].to_sql(query[2], self.con2, if_exists=query[3], chunksize=1000)
                except Exception as e:
                    ui_text = 'Së¡œê·¸í…ìŠ¤íŠ¸' if 's_' in query[2] else 'Cë¡œê·¸í…ìŠ¤íŠ¸'
                    self.windowQ.put((ui_num[ui_text], f'ì˜¤ë¥˜ - Query ê±°ë˜ë””ë¹„ {e}'))

            elif query[0] == 'ì „ëµë””ë¹„':
                try:
                    if len(query) == 2:
                        self.cur3.execute(query[1])
                        self.con3.commit()
                    elif len(query) == 4:
                        query[1].to_sql(query[2], self.con3, if_exists=query[3], chunksize=1000)
                except Exception as e:
                    self.windowQ.put((ui_num['Së¡œê·¸í…ìŠ¤íŠ¸'], f'ì˜¤ë¥˜ - Query ì „ëµë””ë¹„ {e}'))

            elif query[0] == 'ë°±í…Œë””ë¹„':
                try:
                    con = sqlite3.connect(DB_BACKTEST)
                    cur = con.cursor()
                    cur.execute(query[1])
                    con.commit()
                    con.close()
                except Exception as e:
                    self.windowQ.put((ui_num['Së¡œê·¸í…ìŠ¤íŠ¸'], f'ì˜¤ë¥˜ - Query ë°±í…Œë””ë¹„ {e}'))

            elif query == 'í”„ë¡œì„¸ìŠ¤ì¢…ë£Œ':
                break

            self.windowQ.put((ui_num['DBê´€ë¦¬'], 'DBì—…ë°ì´íŠ¸ì™„ë£Œ'))
```

**ì‚¬ìš© ì˜ˆì‹œ:**

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
# ì„¤ì • DBì— ë°ì´í„° ì €ì¥
queryQ.put(('ì„¤ì •ë””ë¹„', df, 'codename', 'replace'))

# ê±°ë˜ DBì— ì²´ê²° ë‚´ì—­ ì €ì¥
queryQ.put(('ê±°ë˜ë””ë¹„', df_chegol, 's_chegeollist', 'append'))

# ì§ì ‘ SQL ì‹¤í–‰
queryQ.put(('ì „ëµë””ë¹„', f"DELETE FROM stockbuy WHERE index='{strategy_name}'"))
```

#### 2. ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì„¤ì •

SQLite ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ PRAGMA ì„¤ì • (ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©):

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
conn = sqlite3.connect(db_path, check_same_thread=False, timeout=30.0)
conn.execute("PRAGMA journal_mode=WAL")        # Write-Ahead Logging
conn.execute("PRAGMA synchronous=NORMAL")      # ë™ê¸°í™” ëª¨ë“œ
conn.execute("PRAGMA cache_size=10000")        # ìºì‹œ í¬ê¸°
conn.execute("PRAGMA temp_store=MEMORY")       # ì„ì‹œ ì €ì¥ì†Œë¥¼ ë©”ëª¨ë¦¬ì—
```

#### 3. ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ ê¸°ëŠ¥ (`utility/query.py:87-256`)

Query í”„ë¡œì„¸ìŠ¤ëŠ” ë‹¤ìŒê³¼ ê°™ì€ DB ê´€ë¦¬ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:

**ë°±í…ŒDBìƒì„±**: ë‚ ì§œë³„ DB íŒŒì¼ë“¤ì„ í•˜ë‚˜ì˜ ë°±í…ŒìŠ¤íŠ¸ìš© DBë¡œ í†µí•©

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
elif 'ë°±í…ŒDBìƒì„±' in query[0]:
    # _database/stock_tick_20240101.db, stock_tick_20240102.db ë“±ì„
    # _database/stock_tick_back.dbë¡œ í†µí•©
```

**ì¼ìDBë¶„ë¦¬**: ë‹¹ì¼ DBë¥¼ ë‚ ì§œë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ ì €ì¥

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
elif 'ì¼ìDBë¶„ë¦¬' in query[0]:
    # stock_tick.dbì—ì„œ ë‚ ì§œë³„ë¡œ stock_tick_20240101.db, stock_tick_20240102.dbë¡œ ë¶„ë¦¬
```

**ì§€ì •ì‹œê°„ì´í›„ì‚­ì œ**: íŠ¹ì • ì‹œê°„ ì´í›„ ë°ì´í„° ì‚­ì œ (ë””ë²„ê¹…/í…ŒìŠ¤íŠ¸ìš©)

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
elif 'ë‹¹ì¼ë°ì´í„°ì§€ì •ì‹œê°„ì´í›„ì‚­ì œ' in query[0]:
    # ì˜ˆ: 093000 ì´í›„ ë°ì´í„° ì‚­ì œ
```

---

## ğŸ“¡ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì‹ 

### ì£¼ì‹ ë°ì´í„° ìˆ˜ì‹  ì‹œìŠ¤í…œ

#### 1. Kiwoom ë¦¬ì‹œë²„ êµ¬ì¡° (`stock/kiwoom_receiver_tick.py:41-118`)

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
class KiwoomReceiverTick:
    """í‚¤ì›€ í‹± ë°ì´í„° ìˆ˜ì‹ ê¸° - ë…ë¦½ í”„ë¡œì„¸ìŠ¤ë¡œ ì‹¤í–‰"""

    def __init__(self, qlist):
        """
        qlist: [kwzservQ, sreceivQ, straderQ, sstgQs, ...]
        - kwzservQ: ë©”ì¸ ìœˆë„ìš°ë¡œ ë©”ì‹œì§€ ì „ì†¡
        - sreceivQ: ë‚´ë¶€ ì—…ë°ì´íŠ¸ìš© í
        - straderQ: íŠ¸ë ˆì´ë” í”„ë¡œì„¸ìŠ¤ë¡œ ë°ì´í„° ì „ì†¡
        - sstgQs: ì „ëµ í”„ë¡œì„¸ìŠ¤ë“¤ë¡œ ë°ì´í„° ì „ì†¡
        """
        app = QApplication(sys.argv)

        self.kwzservQ = qlist[0]
        self.sreceivQ = qlist[1]
        self.straderQ = qlist[2]
        self.sstgQs   = qlist[3]
        self.dict_set = DICT_SET

        # ë°ì´í„° ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
        self.dict_name   = {}  # {ì¢…ëª©ì½”ë“œ: ì¢…ëª©ëª…}
        self.dict_code   = {}  # {ì¢…ëª©ëª…: ì¢…ëª©ì½”ë“œ}
        self.dict_data   = {}  # {ì¢…ëª©ì½”ë“œ: ì‹¤ì‹œê°„ ë°ì´í„°}
        self.dict_mtop   = {}  # {ì‹œê°„: ê±°ë˜ëŒ€ê¸ˆ ìˆœìœ„}

        # Kiwoom API ê°ì²´ ìƒì„± ë° ë¡œê·¸ì¸
        self.kw = Kiwoom(self, 'Receiver')
        self.KiwoomLogin()

        # ZMQ ì„œë²„ ì‹œì‘ (ë¦¬ì‹œë²„ ê³µìœ  ëª¨ë“œ)
        if self.dict_set['ë¦¬ì‹œë²„ê³µìœ '] == 1:
            self.zmqserver = ZmqServ(self.recvservQ)
            self.zmqserver.start()

        # ì—…ë°ì´í„° ìŠ¤ë ˆë“œ ì‹œì‘
        self.updater = Updater(self.sreceivQ)
        self.updater.signal.connect(self.UpdateTuple)
        self.updater.start()

        # ìŠ¤ì¼€ì¤„ëŸ¬ íƒ€ì´ë¨¸
        self.qtimer = QTimer()
        self.qtimer.setInterval(1 * 1000)
        self.qtimer.timeout.connect(self.Scheduler)
        self.qtimer.start()

        app.exec_()

    def KiwoomLogin(self):
        """í‚¤ì›€ ë¡œê·¸ì¸ ë° ì´ˆê¸° ë°ì´í„° ë¡œë“œ"""
        self.kw.CommConnect()  # ë¡œê·¸ì¸
        qtest_qwait(5)
        self.kw.GetConditionLoad()  # ì¡°ê±´ê²€ìƒ‰ì‹ ë¡œë“œ

        # ì½”ìŠ¤ë‹¥, ì½”ìŠ¤í”¼, ETF ì¢…ëª© ë¦¬ìŠ¤íŠ¸
        self.tuple_kosd = tuple(self.kw.GetCodeListByMarket('10'))
        list_code = (self.kw.GetCodeListByMarket('0') +    # ì½”ìŠ¤í”¼
                     self.kw.GetCodeListByMarket('8') +    # ETF
                     list(self.tuple_kosd))                # ì½”ìŠ¤ë‹¥

        # ì¢…ëª© êµ¬ë¶„ ë²ˆí˜¸ (ì „ëµ ë¶„ì‚°ìš©)
        self.dict_sgbn = {code: i % 8 for i, code in enumerate(list_code)}

        # ì¢…ëª©ëª… ë”•ì…”ë„ˆë¦¬ ìƒì„±
        self.dict_name = {code: self.kw.GetMasterCodeName(code) for code in list_code}
        self.dict_code = {name: code for code, name in self.dict_name.items()}

        # ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ì— ì¢…ëª© ì •ë³´ ì „ì†¡
        self.kwzservQ.put(('window', (ui_num['ì¢…ëª©ëª…ë°ì´í„°'],
                                      self.dict_name, self.dict_code, self.dict_sgbn, 'ë”ë¯¸')))
        self.straderQ.put(('ì¢…ëª©êµ¬ë¶„ë²ˆí˜¸', self.dict_sgbn))
        for q in self.sstgQs:
            q.put(('ì¢…ëª©êµ¬ë¶„ë²ˆí˜¸', self.dict_sgbn))
            q.put(('ì½”ìŠ¤ë‹¥ëª©ë¡', self.tuple_kosd))

        # ì¢…ëª©ëª…ì„ DBì— ì €ì¥
        df = pd.DataFrame(self.dict_name.values(), columns=['ì¢…ëª©ëª…'],
                          index=list(self.dict_name.keys()))
        df['ì½”ìŠ¤ë‹¥'] = [True if x in self.tuple_kosd else False for x in df.index]
        self.kwzservQ.put(('query', ('ì„¤ì •ë””ë¹„', df, 'codename', 'replace')))
```

**ì‹¤ì‹œê°„ ë“±ë¡ ë° ë°ì´í„° ì²˜ë¦¬:**

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
# stock/kiwoom_receiver_tick.py:203-235
def OperationRealreg(self):
    """ì¥ ì‹œì‘ ì‹œ ì‹¤ì‹œê°„ ë°ì´í„° ë“±ë¡"""
    self.dict_bool['ë¦¬ì‹œë²„ì‹œì‘'] = True

    # ì¥ìš´ì˜ì‹œê°„ ë“±ë¡
    self.kw.SetRealReg([sn_oper, ' ', '215;20;214', 0])

    # ì—…ì¢…ì§€ìˆ˜ ë“±ë¡
    self.kw.SetRealReg([sn_oper, '001;101', '10;15;20', 1])

    # ì¡°ê±´ê²€ìƒ‰ì‹ìœ¼ë¡œ ì¢…ëª© ê²€ìƒ‰ ë° ì‹¤ì‹œê°„ ë“±ë¡
    self.list_code = self.kw.SendCondition([sn_cond, self.list_cond[1][1],
                                            self.list_cond[1][0], 0])

    # 100ê°œì”© ë¬¶ì–´ì„œ ì‹¤ì‹œê°„ ë“±ë¡
    k = 0
    for i in range(0, len(self.list_code), 100):
        rreg = [sn_gsjm + k, ';'.join(self.list_code[i:i + 100]),
                '10;12;14;30;228;41;61;71;81', 1]
        self.kw.SetRealReg(rreg)
        k += 1

# stock/kiwoom_receiver_tick.py:295-320
def SaveData(self):
    """ì¢…ë£Œ ì‹œ ë°ì´í„°ë¥¼ DBì— ì €ì¥"""
    if len(self.dict_mtop) > 0:
        if self.dict_set['ì£¼ì‹íƒ€ì„í”„ë ˆì„']:
            codes = list(set(';'.join(list(self.dict_mtop.values())[29:]).split(';')))
        else:
            codes = list(set(';'.join(list(self.dict_mtop.values())).split(';')))

        # moneytop í…Œì´ë¸” ì €ì¥
        df = pd.DataFrame({'index': list(self.dict_mtop.keys()),
                           'ê±°ë˜ëŒ€ê¸ˆìˆœìœ„': list(self.dict_mtop.values())})
        con = sqlite3.connect(DB_STOCK_TICK if self.dict_set['ì£¼ì‹íƒ€ì„í”„ë ˆì„']
                              else DB_STOCK_MIN)
        df.to_sql('moneytop', con, index=False, if_exists='append', chunksize=1000)

        # ê° ì¢…ëª© ë°ì´í„° ì €ì¥
        last = len(codes)
        for i, code in enumerate(codes):
            if code in self.dict_data:
                df = pd.DataFrame(self.dict_data[code])
                df.to_sql(code, con, index=False, if_exists='append', chunksize=1000)
        con.close()
```

### ì•”í˜¸í™”í ë°ì´í„° ìˆ˜ì‹  ì‹œìŠ¤í…œ

#### 1. Upbit ë¦¬ì‹œë²„ êµ¬ì¡° (`coin/upbit_receiver_tick.py:30-150`)

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
class UpbitReceiverTick:
    """ì—…ë¹„íŠ¸ í‹± ë°ì´í„° ìˆ˜ì‹ ê¸° - ë…ë¦½ í”„ë¡œì„¸ìŠ¤ë¡œ ì‹¤í–‰"""

    def __init__(self, qlist):
        """
        qlist: [windowQ, soundQ, queryQ, teleQ, chartQ, hogaQ, webcQ, backQ,
                creceivQ, ctraderQ, cstgQ, liveQ, kimpQ, wdzservQ, totalQ]
        """
        self.windowQ  = qlist[0]
        self.soundQ   = qlist[1]
        self.queryQ   = qlist[2]
        self.teleQ    = qlist[3]
        self.hogaQ    = qlist[5]
        self.creceivQ = qlist[8]  # WebSocket ìˆ˜ì‹ ìš© í
        self.ctraderQ = qlist[9]
        self.cstgQ    = qlist[10]
        self.dict_set = DICT_SET

        # ë°ì´í„° ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
        self.dict_tmdt   = {}  # {ì¢…ëª©: ì‹œê°„ë³„ ë°ì´í„°}
        self.dict_data   = {}  # {ì¢…ëª©: ì‹¤ì‹œê°„ ë°ì´í„°}
        self.dict_mtop   = {}  # {ì‹œê°„: ê±°ë˜ëŒ€ê¸ˆ ìˆœìœ„}

        # ê±°ë˜ì†Œ í‹°ì»¤ ì •ë³´ ë¡œë“œ
        self.GetTickers()

        # WebSocket ì‹œì‘
        self.WebSocketsStart(self.creceivQ)

        self.MainLoop()

    def MainLoop(self):
        """ë©”ì¸ ë£¨í”„: WebSocketì—ì„œ ìˆ˜ì‹ í•œ ë°ì´í„° ì²˜ë¦¬"""
        text = 'ì½”ì¸ ë¦¬ì‹œë²„ë¥¼ ì‹œì‘í•˜ì˜€ìŠµë‹ˆë‹¤.'
        if self.dict_set['ì½”ì¸ì•Œë¦¼ì†Œë¦¬']: self.soundQ.put(text)
        self.teleQ.put(text)
        self.windowQ.put((ui_num['Cë‹¨ìˆœí…ìŠ¤íŠ¸'], 'ì‹œìŠ¤í…œ ëª…ë ¹ ì‹¤í–‰ ì•Œë¦¼ - ë¦¬ì‹œë²„ ì‹œì‘'))

        while True:
            data = self.creceivQ.get()
            curr_time = now()

            if type(data) == tuple:
                # UI/íŠ¸ë ˆì´ë”/ì „ëµ í”„ë¡œì„¸ìŠ¤ë¡œë¶€í„°ì˜ ëª…ë ¹ ì²˜ë¦¬
                self.UpdateTuple(data)

            elif type(data) == dict:
                # WebSocketìœ¼ë¡œë¶€í„° ìˆ˜ì‹ í•œ ë°ì´í„°
                if data['type'] == 'ticker':
                    try:
                        # UTC ì‹œê°„ì„ í•œêµ­ ì‹œê°„ìœ¼ë¡œ ë³€í™˜ (-32400ì´ˆ = -9ì‹œê°„)
                        dt   = int(strf_time('%Y%m%d%H%M%S',
                                             from_timestamp(int(data['timestamp'] / 1000 - 32400))))
                        if self.dict_set['ì½”ì¸ì „ëµì¢…ë£Œì‹œê°„'] < int(str(dt)[8:]): continue

                        code = data['code']         # KRW-BTC
                        c    = data['trade_price']  # í˜„ì¬ê°€
                        o    = data['opening_price']
                        h    = data['high_price']
                        low  = data['low_price']
                        per  = round(data['signed_change_rate'] * 100, 2)
                        tbids = data['acc_bid_volume']   # ëˆ„ì ë§¤ìˆ˜ëŸ‰
                        tasks = data['acc_ask_volume']   # ëˆ„ì ë§¤ë„ëŸ‰
                        dm   = data['acc_trade_price']   # ë‹¹ì¼ê±°ë˜ëŒ€ê¸ˆ

                        self.UpdateTickData(code, c, o, h, low, per, dm, tbids, tasks, dt)

                    except Exception as e:
                        self.windowQ.put((ui_num['Cë‹¨ìˆœí…ìŠ¤íŠ¸'],
                                         f'ì‹œìŠ¤í…œ ëª…ë ¹ ì˜¤ë¥˜ ì•Œë¦¼ - ì›¹ì†Œì¼“ ticker {e}'))

                elif data['type'] == 'orderbook':
                    # í˜¸ê°€ ë°ì´í„° ì²˜ë¦¬
                    try:
                        dt   = int(strf_time('%Y%m%d%H%M%S',
                                             from_timestamp(int(data['timestamp'] / 1000 - 32400))))
                        code = data['code']
                        hoga_tamount = (data['total_ask_size'], data['total_bid_size'])
                        data = data['orderbook_units']

                        # ë§¤ë„í˜¸ê°€ 10~1 (ì—­ìˆœ)
                        hoga_seprice = (data[9]['ask_price'], data[8]['ask_price'], ..., data[0]['ask_price'])
                        # ë§¤ìˆ˜í˜¸ê°€ 1~10
                        hoga_buprice = (data[0]['bid_price'], data[1]['bid_price'], ..., data[9]['bid_price'])
                        # ë§¤ë„ì”ëŸ‰ 10~1, ë§¤ìˆ˜ì”ëŸ‰ 1~10
                        hoga_samount = (...)
                        hoga_bamount = (...)

                        self.UpdateHogaData(dt, hoga_tamount, hoga_seprice, hoga_buprice,
                                            hoga_samount, hoga_bamount, code, curr_time)

                    except Exception as e:
                        self.windowQ.put((ui_num['Cë‹¨ìˆœí…ìŠ¤íŠ¸'],
                                         f'ì‹œìŠ¤í…œ ëª…ë ¹ ì˜¤ë¥˜ ì•Œë¦¼ - ì›¹ì†Œì¼“ orderbook {e}'))

            elif data == 'í”„ë¡œì„¸ìŠ¤ì¢…ë£Œ':
                self.SysExit()
                break

            # 1ì´ˆë§ˆë‹¤ ê±°ë˜ëŒ€ê¸ˆ ìˆœìœ„ ì „ì†¡
            if curr_time > self.dict_time['ê±°ë˜ëŒ€ê¸ˆìˆœìœ„ì „ì†¡']:
                self.UpdateMoneyTop()
                self.dict_time['ê±°ë˜ëŒ€ê¸ˆìˆœìœ„ì „ì†¡'] = timedelta_sec(1)
```

**WebSocket ì‹œì‘:**

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
# coin/upbit_receiver_tick.py
def WebSocketsStart(self, creceivQ):
    """Upbit WebSocket í”„ë¡œì„¸ìŠ¤ ì‹œì‘"""
    codes = [x for x in self.dict_daym.keys()]  # ê±°ë˜ ê°€ëŠ¥í•œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸
    self.proc_webs = Process(target=WebSocketReceiver, args=(creceivQ, codes), daemon=True)
    self.proc_webs.start()

# coin/upbit_websocket.py
class WebSocketReceiver:
    """Upbit WebSocket ì „ë‹´ í”„ë¡œì„¸ìŠ¤"""
    async def connect_websocket(self):
        uri = "wss://api.upbit.com/websocket/v1"
        async with websockets.connect(uri) as websocket:
            subscribe_msg = [
                {"ticket": "stom"},
                {"type": "ticker", "codes": self.codes},
                {"type": "orderbook", "codes": self.codes}
            ]
            await websocket.send(json.dumps(subscribe_msg))

            while True:
                data = await websocket.recv()
                data = json.loads(data.decode('utf-8'))
                self.recvQ.put(data)  # ë©”ì¸ ë¦¬ì‹œë²„ë¡œ ë°ì´í„° ì „ì†¡
```

#### 2. Binance ë¦¬ì‹œë²„ êµ¬ì¡° (`coin/binance_receiver_tick.py:31-100`)

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
class BinanceReceiverTick:
    """ë°”ì´ë‚¸ìŠ¤ ì„ ë¬¼ í‹± ë°ì´í„° ìˆ˜ì‹ ê¸°"""

    def __init__(self, qlist):
        self.windowQ  = qlist[0]
        self.creceivQ = qlist[8]
        self.ctraderQ = qlist[9]
        self.cstgQ    = qlist[10]
        self.binance  = binance.Client()  # ë°”ì´ë‚¸ìŠ¤ API í´ë¼ì´ì–¸íŠ¸

        # ê±°ë˜ ê°€ëŠ¥í•œ ì„ ë¬¼ ì¢…ëª© ë¡œë“œ
        self.codes = self.GetTickers()

        # WebSocket ì‹œì‘
        self.WebSocketsStart(self.creceivQ)
        self.MainLoop()

    def MainLoop(self):
        """ë©”ì¸ ë£¨í”„: WebSocket ë°ì´í„° ì²˜ë¦¬"""
        while True:
            data = self.creceivQ.get()

            if type(data) == list:
                if data[0] == 'trade':
                    # ì‹¤ì‹œê°„ ì²´ê²° ë°ì´í„°
                    code = data[1]['s']  # BTCUSDT
                    c = float(data[1]['p'])  # ì²´ê²°ê°€
                    # ... ë°ì´í„° ì²˜ë¦¬ ...

                elif data[0] == 'depth':
                    # í˜¸ê°€ ë°ì´í„°
                    code = data[1]['s']
                    asks = data[1]['a']  # [[price, qty], ...]
                    bids = data[1]['b']
                    # ... í˜¸ê°€ ì²˜ë¦¬ ...

            elif type(data) == tuple:
                self.UpdateTuple(data)

            elif data == 'í”„ë¡œì„¸ìŠ¤ì¢…ë£Œ':
                self.SysExit()
                break
```

---

## ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ë° ê²€ì¦

STOM ì‹œìŠ¤í…œì€ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì‹  ì‹œ ìë™ìœ¼ë¡œ ë°ì´í„° ì „ì²˜ë¦¬ì™€ ê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

### ë°ì´í„° ì •ì œ ë° í•„í„°ë§

**ì£¼ì‹ ë°ì´í„° ì „ì²˜ë¦¬** (`stock/kiwoom_receiver_tick.py`):
- ê°€ê²© ë°ì´í„° ì ˆëŒ“ê°’ ë³€í™˜
- VI(ë³€ë™ì„±ì™„í™”ì¥ì¹˜) ë°œë™ ì¢…ëª© ì²˜ë¦¬
- ìƒí•œê°€/í•˜í•œê°€ ì •ë³´ ê³„ì‚° ë° ì €ì¥
- ê±°ë˜ì •ì§€ ì¢…ëª© í•„í„°ë§
- ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì¢…ëª© ì œì™¸

**ì•”í˜¸í™”í ë°ì´í„° ì „ì²˜ë¦¬** (`coin/upbit_receiver_tick.py`, `coin/binance_receiver_tick.py`):
- UTC ì‹œê°„ â†’ KST ì‹œê°„ ë³€í™˜ (-32400ì´ˆ)
- ì†Œìˆ˜ì  ì •ë°€ë„ ì¡°ì •
- ê±°ë˜ëŸ‰ 0ì¸ ì¢…ëª© í•„í„°ë§
- ê±°ë˜ ì •ì§€ ë§ˆì¼“ ì œì™¸

### ê±°ë˜ëŒ€ê¸ˆ ìˆœìœ„ ê¸°ë°˜ í•„í„°ë§

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
# ê±°ë˜ëŒ€ê¸ˆ ìƒìœ„ ì¢…ëª©ë§Œ DBì— ì €ì¥ (ë©”ëª¨ë¦¬/ìŠ¤í† ë¦¬ì§€ ìµœì í™”)
# í‹± ëª¨ë“œ: ê±°ë˜ëŒ€ê¸ˆ ìˆœìœ„ 30ìœ„ ì´í›„ ì¢…ëª©ë§Œ ì €ì¥
# ë¶„ë´‰ ëª¨ë“œ: ëª¨ë“  ê±°ë˜ëŒ€ê¸ˆ ìˆœìœ„ ì¢…ëª© ì €ì¥
```

### ë°ì´í„° ê²€ì¦ ì‹œìŠ¤í…œ (í•™ìŠµìš© ì˜ˆì œ)

ì‹¤ì‹œê°„ ë°ì´í„°ì˜ í’ˆì§ˆì„ ë³´ì¥í•˜ê¸° ìœ„í•œ ê²€ì¦ ì‹œìŠ¤í…œ ì˜ˆì œì…ë‹ˆë‹¤:

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
class DataValidator:
    """ë°ì´í„° ê²€ì¦ í´ë˜ìŠ¤ - ì‹¤ì‹œê°„ ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬"""

    def __init__(self):
        # ë°ì´í„° ìœ í˜•ë³„ ê²€ì¦ ê·œì¹™ ì •ì˜
        self.validation_rules = {
            'stock_tick': {
                'current_price': {'min': 1, 'max': 1000000, 'type': int},
                'volume': {'min': 0, 'max': 999999999, 'type': int},
                'change_rate': {'min': -30.0, 'max': 30.0, 'type': float}
            },
            'coin_tick': {
                'trade_price': {'min': 0.0001, 'max': 1000000, 'type': float},
                'trade_volume': {'min': 0, 'max': 999999999, 'type': float},
                'change_rate': {'min': -50.0, 'max': 50.0, 'type': float}
            }
        }

    def validate_data(self, data_type, data):
        """ë°ì´í„° ê²€ì¦ - ê·œì¹™ ê¸°ë°˜ ìœ íš¨ì„± í™•ì¸"""
        rules = self.validation_rules.get(data_type, {})
        errors = []

        for field, rule in rules.items():
            if field in data:
                value = data[field]

                # ë²”ìœ„ ê²€ì¦
                if 'min' in rule and value < rule['min']:
                    errors.append(f"{field} ê°’ì´ ìµœì†Œê°’({rule['min']})ë³´ë‹¤ ì‘ìŒ: {value}")

                if 'max' in rule and value > rule['max']:
                    errors.append(f"{field} ê°’ì´ ìµœëŒ€ê°’({rule['max']})ë³´ë‹¤ í¼: {value}")

                # íƒ€ì… ê²€ì¦
                if 'type' in rule and not isinstance(value, rule['type']):
                    errors.append(f"{field} íƒ€ì… ì˜¤ë¥˜: {type(value)} != {rule['type']}")

        return len(errors) == 0, errors

    def clean_data(self, data_type, data):
        """ë°ì´í„° ì •ì œ - ë¹„ì •ìƒ ë°ì´í„° ë³´ì •"""
        if data_type == 'stock_tick':
            # ê°€ê²© ë°ì´í„° ì ˆëŒ“ê°’ ì²˜ë¦¬ (í‚¤ì›€ APIëŠ” ìŒìˆ˜ë¡œ í•˜ë½ í‘œì‹œ)
            if 'current_price' in data:
                data['current_price'] = abs(data['current_price'])

            # ê±°ë˜ëŸ‰ 0 ì´í•˜ ê°’ ì²˜ë¦¬
            if 'volume' in data and data['volume'] <= 0:
                data['volume'] = 0

            # ë“±ë½ë¥  ë²”ìœ„ ì œí•œ
            if 'change_rate' in data:
                data['change_rate'] = max(-30.0, min(30.0, data['change_rate']))

        elif data_type == 'coin_tick':
            # ì†Œìˆ˜ì  ì •ë°€ë„ ì¡°ì • (ë¹„íŠ¸ì½”ì¸ ë“±ì€ 8ìë¦¬ê¹Œì§€)
            if 'trade_price' in data:
                data['trade_price'] = round(data['trade_price'], 8)

            # ê±°ë˜ëŸ‰ ì •ë°€ë„
            if 'trade_volume' in data:
                data['trade_volume'] = round(data['trade_volume'], 8)

        return data

# ì‚¬ìš© ì˜ˆì‹œ
validator = DataValidator()

# ì£¼ì‹ í‹± ë°ì´í„° ê²€ì¦
stock_data = {
    'code': '005930',
    'current_price': 75000,
    'volume': 1000000,
    'change_rate': 2.5
}
is_valid, errors = validator.validate_data('stock_tick', stock_data)
if is_valid:
    cleaned_data = validator.clean_data('stock_tick', stock_data)
    print("ê²€ì¦ í†µê³¼:", cleaned_data)
else:
    print("ê²€ì¦ ì‹¤íŒ¨:", errors)
```

### ì´ìƒì¹˜ íƒì§€ ì‹œìŠ¤í…œ (í•™ìŠµìš© ì˜ˆì œ)

í†µê³„ì  ë°©ë²•ì„ ì‚¬ìš©í•œ ì´ìƒì¹˜ íƒì§€ ì˜ˆì œì…ë‹ˆë‹¤:

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
from collections import deque
import numpy as np

class OutlierDetector:
    """ì´ìƒì¹˜ íƒì§€ í´ë˜ìŠ¤ - Z-score ê¸°ë°˜"""

    def __init__(self, window_size=100):
        """
        Args:
            window_size: ì´ë™ í‰ê·  ê³„ì‚° ìœˆë„ìš° í¬ê¸°
        """
        self.window_size = window_size
        self.price_history = {}  # {ì¢…ëª©ì½”ë“œ: ê°€ê²© íˆìŠ¤í† ë¦¬}
        self.volume_history = {}  # {ì¢…ëª©ì½”ë“œ: ê±°ë˜ëŸ‰ íˆìŠ¤í† ë¦¬}

    def detect_price_outlier(self, symbol, current_price):
        """
        ê°€ê²© ì´ìƒì¹˜ íƒì§€ - Z-score ë°©ì‹

        Z-score = (X - Î¼) / Ïƒ
        - X: í˜„ì¬ ê°€ê²©
        - Î¼: í‰ê·  ê°€ê²©
        - Ïƒ: í‘œì¤€í¸ì°¨

        ì¼ë°˜ì ìœ¼ë¡œ |Z-score| > 3 ì´ë©´ ì´ìƒì¹˜ë¡œ íŒë‹¨
        """
        if symbol not in self.price_history:
            self.price_history[symbol] = deque(maxlen=self.window_size)

        history = self.price_history[symbol]

        # ìµœì†Œ ë°ì´í„° í•„ìš” (í†µê³„ì  ì‹ ë¢°ì„±)
        if len(history) < 10:
            history.append(current_price)
            return False, 0.0

        # í†µê³„ê°’ ê³„ì‚°
        mean_price = np.mean(history)
        std_price = np.std(history)

        if std_price == 0:  # í‘œì¤€í¸ì°¨ê°€ 0ì´ë©´ ëª¨ë“  ê°’ì´ ë™ì¼
            history.append(current_price)
            return False, 0.0

        # Z-score ê³„ì‚°
        z_score = abs((current_price - mean_price) / std_price)

        # Z-score > 3ì´ë©´ ì´ìƒì¹˜ë¡œ íŒë‹¨ (99.7% ì‹ ë¢°êµ¬ê°„ ì´ˆê³¼)
        is_outlier = z_score > 3

        if not is_outlier:
            history.append(current_price)

        return is_outlier, z_score

    def detect_volume_spike(self, symbol, current_volume):
        """
        ê±°ë˜ëŸ‰ ê¸‰ì¦ íƒì§€

        í‰ê·  ê±°ë˜ëŸ‰ì˜ 5ë°° ì´ìƒì´ë©´ ê¸‰ì¦ìœ¼ë¡œ íŒë‹¨
        (í…Œë§ˆì£¼, ë‰´ìŠ¤ ë“±ì˜ ì˜í–¥)
        """
        if symbol not in self.volume_history:
            self.volume_history[symbol] = deque(maxlen=self.window_size)

        history = self.volume_history[symbol]

        if len(history) < 10:
            history.append(current_volume)
            return False, 0.0

        avg_volume = np.mean(history)

        if avg_volume == 0:
            history.append(current_volume)
            return False, 0.0

        # ê±°ë˜ëŸ‰ ë°°ìˆ˜ ê³„ì‚°
        volume_ratio = current_volume / avg_volume

        # í‰ê· ì˜ 5ë°° ì´ìƒì´ë©´ ê¸‰ì¦
        is_spike = volume_ratio > 5.0

        history.append(current_volume)
        return is_spike, volume_ratio

# ì‚¬ìš© ì˜ˆì‹œ
detector = OutlierDetector(window_size=100)

# ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬
for tick in real_time_data:
    # ê°€ê²© ì´ìƒì¹˜ ê²€ì‚¬
    is_outlier, z_score = detector.detect_price_outlier(
        tick['code'],
        tick['current_price']
    )
    if is_outlier:
        print(f"ê°€ê²© ì´ìƒì¹˜ ê°ì§€: {tick['code']}, Z-score: {z_score:.2f}")

    # ê±°ë˜ëŸ‰ ê¸‰ì¦ ê²€ì‚¬
    is_spike, ratio = detector.detect_volume_spike(
        tick['code'],
        tick['volume']
    )
    if is_spike:
        print(f"ê±°ë˜ëŸ‰ ê¸‰ì¦: {tick['code']}, ë°°ìˆ˜: {ratio:.2f}ë°°")
```

---

## ğŸ“ˆ ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬

### í‹±/ë¶„ë´‰ ë°ì´í„° ì§‘ê³„

STOMì€ í‹± ë°ì´í„°ì™€ ë¶„ë´‰ ë°ì´í„°ë¥¼ ë³„ë„ë¡œ ìˆ˜ì§‘í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.

**í‹± ë°ì´í„°** (`ì£¼ì‹íƒ€ì„í”„ë ˆì„=1`, `ì½”ì¸íƒ€ì„í”„ë ˆì„=1`):
- ì‹¤ì‹œê°„ ì²´ê²° ë°œìƒ ì‹œë§ˆë‹¤ ë°ì´í„° ì €ì¥
- ì‹œê°„: YYYYMMDDHHMMSS (ì´ˆ ë‹¨ìœ„)

**ë¶„ë´‰ ë°ì´í„°** (`ì£¼ì‹íƒ€ì„í”„ë ˆì„=0`, `ì½”ì¸íƒ€ì„í”„ë ˆì„=0`):
- 1ë¶„ë§ˆë‹¤ OHLCV ë°ì´í„° ìƒì„± ë° ì €ì¥
- ì‹œê°„: YYYYMMDDHHMM00 (ë¶„ ë‹¨ìœ„, ì´ˆëŠ” 00 ê³ ì •)

**ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°**:
- ì „ëµ í”„ë¡œì„¸ìŠ¤(`*_strategy_*.py`)ì—ì„œ í•„ìš”í•œ ì§€í‘œ ê³„ì‚°
- TA-Lib ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©
- ì´ë™í‰ê· , RSI, MACD, ë³¼ë¦°ì €ë°´ë“œ ë“±

### OHLCV ë°ì´í„° ì§‘ê³„ ì‹œìŠ¤í…œ (í•™ìŠµìš© ì˜ˆì œ)

í‹± ë°ì´í„°ë¥¼ ì‹œê°„í”„ë ˆì„ë³„ OHLCV ìº”ë“¤ë¡œ ì§‘ê³„í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤:

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
from datetime import datetime
from collections import defaultdict

class OHLCVAggregator:
    """OHLCV ë°ì´í„° ì§‘ê³„ê¸° - í‹±ì„ ìº”ë“¤ë¡œ ë³€í™˜"""

    def __init__(self):
        self.tick_buffers = {}  # {ì¢…ëª©: {ì‹œê°„í”„ë ˆì„: [í‹±ë°ì´í„°]}}
        self.timeframes = ['1m', '5m', '15m', '1h', '4h', '1d']

    def add_tick(self, symbol, tick_data):
        """
        í‹± ë°ì´í„° ì¶”ê°€ ë° ì§‘ê³„ ì²´í¬

        Args:
            symbol: ì¢…ëª©ì½”ë“œ ë˜ëŠ” ë§ˆì¼“
            tick_data: {'price': ê°€ê²©, 'volume': ê±°ë˜ëŸ‰, 'timestamp': ì‹œê°„}
        """
        if symbol not in self.tick_buffers:
            self.tick_buffers[symbol] = {tf: [] for tf in self.timeframes}

        # ëª¨ë“  ì‹œê°„í”„ë ˆì„ ë²„í¼ì— í‹± ì¶”ê°€
        for timeframe in self.timeframes:
            self.tick_buffers[symbol][timeframe].append(tick_data)

        # ì‹œê°„í”„ë ˆì„ë³„ ì§‘ê³„ í•„ìš” ì—¬ë¶€ í™•ì¸
        self.check_aggregation(symbol, tick_data['timestamp'])

    def check_aggregation(self, symbol, timestamp):
        """ì§‘ê³„ ì‹œì  í™•ì¸ ë° ì‹¤í–‰"""
        for timeframe in self.timeframes:
            if self.should_aggregate(timeframe, timestamp):
                ohlcv = self.aggregate_ticks(symbol, timeframe)
                if ohlcv:
                    self.save_ohlcv(symbol, timeframe, ohlcv)
                    # ë²„í¼ í´ë¦¬ì–´
                    self.tick_buffers[symbol][timeframe] = []

    def should_aggregate(self, timeframe, timestamp):
        """
        ì§‘ê³„ í•„ìš” ì—¬ë¶€ íŒë‹¨

        Args:
            timeframe: ì‹œê°„í”„ë ˆì„ ('1m', '5m', etc.)
            timestamp: í˜„ì¬ ì‹œê°„

        Returns:
            bool: ì§‘ê³„ í•„ìš” ì—¬ë¶€
        """
        if timeframe == '1m':
            # ë¶„ì´ ë°”ë€Œë©´ ì§‘ê³„ (00ì´ˆ)
            return timestamp.second == 0

        elif timeframe == '5m':
            # 5ë¶„ë§ˆë‹¤ ì§‘ê³„ (0, 5, 10, 15, ... ë¶„ì˜ 00ì´ˆ)
            return timestamp.minute % 5 == 0 and timestamp.second == 0

        elif timeframe == '15m':
            # 15ë¶„ë§ˆë‹¤ ì§‘ê³„
            return timestamp.minute % 15 == 0 and timestamp.second == 0

        elif timeframe == '1h':
            # 1ì‹œê°„ë§ˆë‹¤ ì§‘ê³„ (ë§¤ ì‹œ 00ë¶„ 00ì´ˆ)
            return timestamp.minute == 0 and timestamp.second == 0

        elif timeframe == '4h':
            # 4ì‹œê°„ë§ˆë‹¤ ì§‘ê³„ (0, 4, 8, 12, 16, 20ì‹œ)
            return (timestamp.hour % 4 == 0 and
                    timestamp.minute == 0 and
                    timestamp.second == 0)

        elif timeframe == '1d':
            # ì¼ë´‰ ì§‘ê³„ (00:00:00)
            return (timestamp.hour == 0 and
                    timestamp.minute == 0 and
                    timestamp.second == 0)

        return False

    def aggregate_ticks(self, symbol, timeframe):
        """
        í‹± ë°ì´í„°ë¥¼ OHLCVë¡œ ì§‘ê³„

        Returns:
            dict: {'symbol', 'timeframe', 'open', 'high', 'low', 'close', 'volume', 'timestamp'}
        """
        ticks = self.tick_buffers[symbol][timeframe]

        if not ticks:
            return None

        # ê°€ê²©ê³¼ ê±°ë˜ëŸ‰ ì¶”ì¶œ
        prices = [tick['price'] for tick in ticks]
        volumes = [tick['volume'] for tick in ticks]

        # OHLCV ìƒì„±
        ohlcv = {
            'symbol': symbol,
            'timeframe': timeframe,
            'open': prices[0],           # ì²« ê±°ë˜ ê°€ê²©
            'high': max(prices),          # ìµœê³ ê°€
            'low': min(prices),           # ìµœì €ê°€
            'close': prices[-1],          # ë§ˆì§€ë§‰ ê±°ë˜ ê°€ê²©
            'volume': sum(volumes),       # ëˆ„ì  ê±°ë˜ëŸ‰
            'timestamp': self.get_candle_timestamp(ticks[0]['timestamp'], timeframe)
        }

        return ohlcv

    def get_candle_timestamp(self, timestamp, timeframe):
        """
        ìº”ë“¤ íƒ€ì„ìŠ¤íƒ¬í”„ ê³„ì‚° - ì‹œê°„í”„ë ˆì„ ì‹œì‘ ì‹œê°„

        ì˜ˆ: 09:03:45ì˜ 1ë¶„ë´‰ íƒ€ì„ìŠ¤íƒ¬í”„ = 09:03:00
        """
        if timeframe == '1m':
            return timestamp.replace(second=0, microsecond=0)

        elif timeframe == '5m':
            # 5ë¶„ ë‹¨ìœ„ë¡œ ë‚´ë¦¼
            minute = (timestamp.minute // 5) * 5
            return timestamp.replace(minute=minute, second=0, microsecond=0)

        elif timeframe == '15m':
            minute = (timestamp.minute // 15) * 15
            return timestamp.replace(minute=minute, second=0, microsecond=0)

        elif timeframe == '1h':
            return timestamp.replace(minute=0, second=0, microsecond=0)

        elif timeframe == '4h':
            hour = (timestamp.hour // 4) * 4
            return timestamp.replace(hour=hour, minute=0, second=0, microsecond=0)

        elif timeframe == '1d':
            return timestamp.replace(hour=0, minute=0, second=0, microsecond=0)

    def save_ohlcv(self, symbol, timeframe, ohlcv):
        """OHLCV ë°ì´í„°ë¥¼ DBì— ì €ì¥"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” DB ì €ì¥
        print(f"OHLCV ì €ì¥: {symbol} {timeframe} {ohlcv}")

# ì‚¬ìš© ì˜ˆì‹œ
aggregator = OHLCVAggregator()

# ì‹¤ì‹œê°„ í‹± ë°ì´í„° ìˆ˜ì‹  ì‹œë®¬ë ˆì´ì…˜
sample_ticks = [
    {'price': 75000, 'volume': 100, 'timestamp': datetime(2024, 1, 1, 9, 0, 0)},
    {'price': 75100, 'volume': 150, 'timestamp': datetime(2024, 1, 1, 9, 0, 15)},
    {'price': 75200, 'volume': 200, 'timestamp': datetime(2024, 1, 1, 9, 0, 30)},
    {'price': 75050, 'volume': 180, 'timestamp': datetime(2024, 1, 1, 9, 0, 45)},
    {'price': 75150, 'volume': 120, 'timestamp': datetime(2024, 1, 1, 9, 1, 0)},  # 1ë¶„ ê²½ê³„
]

for tick in sample_ticks:
    aggregator.add_tick('005930', tick)
```

### ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° (í•™ìŠµìš© ì˜ˆì œ)

ì£¼ìš” ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì˜ˆì œì…ë‹ˆë‹¤:

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
import numpy as np

class TechnicalIndicators:
    """ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° í´ë˜ìŠ¤"""

    @staticmethod
    def simple_moving_average(prices, period):
        """
        ë‹¨ìˆœ ì´ë™í‰ê·  (SMA - Simple Moving Average)

        SMA = (P1 + P2 + ... + Pn) / n

        Args:
            prices: ê°€ê²© ë¦¬ìŠ¤íŠ¸
            period: ê¸°ê°„

        Returns:
            float: SMA ê°’
        """
        if len(prices) < period:
            return None

        return sum(prices[-period:]) / period

    @staticmethod
    def exponential_moving_average(prices, period, alpha=None):
        """
        ì§€ìˆ˜ ì´ë™í‰ê·  (EMA - Exponential Moving Average)

        EMA_today = Î± Ã— Price_today + (1-Î±) Ã— EMA_yesterday
        Î± = 2 / (period + 1)

        ìµœê·¼ ë°ì´í„°ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬

        Args:
            prices: ê°€ê²© ë¦¬ìŠ¤íŠ¸
            period: ê¸°ê°„
            alpha: í‰í™œ ê³„ìˆ˜ (ê¸°ë³¸ê°’: 2/(period+1))

        Returns:
            float: EMA ê°’
        """
        if len(prices) < 1:
            return None

        if alpha is None:
            alpha = 2 / (period + 1)

        ema = prices[0]
        for price in prices[1:]:
            ema = alpha * price + (1 - alpha) * ema

        return ema

    @staticmethod
    def bollinger_bands(prices, period=20, std_dev=2):
        """
        ë³¼ë¦°ì € ë°´ë“œ (Bollinger Bands)

        Middle Band = SMA(20)
        Upper Band = Middle Band + (2 Ã— Ïƒ)
        Lower Band = Middle Band - (2 Ã— Ïƒ)

        ê°€ê²© ë³€ë™ì„± ì¸¡ì • ë° ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ íŒë‹¨

        Args:
            prices: ê°€ê²© ë¦¬ìŠ¤íŠ¸
            period: ê¸°ê°„ (ê¸°ë³¸ 20)
            std_dev: í‘œì¤€í¸ì°¨ ë°°ìˆ˜ (ê¸°ë³¸ 2)

        Returns:
            tuple: (ìƒë‹¨ë°´ë“œ, ì¤‘ê°„ë°´ë“œ, í•˜ë‹¨ë°´ë“œ)
        """
        if len(prices) < period:
            return None, None, None

        # ì¤‘ê°„ ë°´ë“œ (SMA)
        sma = TechnicalIndicators.simple_moving_average(prices, period)

        # í‘œì¤€í¸ì°¨ ê³„ì‚°
        std = np.std(prices[-period:])

        # ìƒë‹¨/í•˜ë‹¨ ë°´ë“œ
        upper_band = sma + (std_dev * std)
        lower_band = sma - (std_dev * std)

        return upper_band, sma, lower_band

    @staticmethod
    def rsi(prices, period=14):
        """
        ìƒëŒ€ê°•ë„ì§€ìˆ˜ (RSI - Relative Strength Index)

        RSI = 100 - (100 / (1 + RS))
        RS = í‰ê·  ìƒìŠ¹í­ / í‰ê·  í•˜ë½í­

        ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ íŒë‹¨:
        - RSI > 70: ê³¼ë§¤ìˆ˜ (ë§¤ë„ ì‹ í˜¸)
        - RSI < 30: ê³¼ë§¤ë„ (ë§¤ìˆ˜ ì‹ í˜¸)

        Args:
            prices: ê°€ê²© ë¦¬ìŠ¤íŠ¸
            period: ê¸°ê°„ (ê¸°ë³¸ 14)

        Returns:
            float: RSI ê°’ (0-100)
        """
        if len(prices) < period + 1:
            return None

        # ê°€ê²© ë³€í™”ëŸ‰ ê³„ì‚°
        deltas = np.diff(prices)

        # ìƒìŠ¹/í•˜ë½ ë¶„ë¦¬
        gains = np.where(deltas > 0, deltas, 0)
        losses = np.where(deltas < 0, -deltas, 0)

        # í‰ê·  ìƒìŠ¹/í•˜ë½í­
        avg_gain = np.mean(gains[-period:])
        avg_loss = np.mean(losses[-period:])

        if avg_loss == 0:
            return 100  # í•˜ë½ì´ ì—†ìœ¼ë©´ RSI = 100

        # RSì™€ RSI ê³„ì‚°
        rs = avg_gain / avg_loss
        rsi = 100 - (100 / (1 + rs))

        return rsi

    @staticmethod
    def macd(prices, fast_period=12, slow_period=26, signal_period=9):
        """
        MACD (Moving Average Convergence Divergence)

        MACD Line = EMA(12) - EMA(26)
        Signal Line = EMA(MACD, 9)
        Histogram = MACD Line - Signal Line

        ì¶”ì„¸ ì „í™˜ ë° ë§¤ë§¤ ì‹ í˜¸ í¬ì°©

        Args:
            prices: ê°€ê²© ë¦¬ìŠ¤íŠ¸
            fast_period: ë¹ ë¥¸ EMA ê¸°ê°„
            slow_period: ëŠë¦° EMA ê¸°ê°„
            signal_period: ì‹œê·¸ë„ EMA ê¸°ê°„

        Returns:
            tuple: (MACDì„ , ì‹œê·¸ë„ì„ , íˆìŠ¤í† ê·¸ë¨)
        """
        if len(prices) < slow_period:
            return None, None, None

        # ë¹ ë¥¸/ëŠë¦° EMA ê³„ì‚°
        fast_ema = TechnicalIndicators.exponential_moving_average(prices, fast_period)
        slow_ema = TechnicalIndicators.exponential_moving_average(prices, slow_period)

        if fast_ema is None or slow_ema is None:
            return None, None, None

        # MACD ì„ 
        macd_line = fast_ema - slow_ema

        # ì‹œê·¸ë„ ì„  ê³„ì‚°ì„ ìœ„í•œ MACD íˆìŠ¤í† ë¦¬ í•„ìš”
        # ê°„ë‹¨í•œ ì˜ˆì œë¥¼ ìœ„í•´ í˜„ì¬ ê°’ë§Œ ë°˜í™˜
        # ì‹¤ì œë¡œëŠ” MACD ê°’ë“¤ì˜ EMAë¥¼ ê³„ì‚°í•´ì•¼ í•¨

        return macd_line, None, None

# ì‚¬ìš© ì˜ˆì‹œ
prices = [75000, 75100, 75200, 74900, 75300, 75400, 75100, 75500,
          75600, 75400, 75700, 75800, 75600, 75900, 76000]

# SMA ê³„ì‚°
sma_5 = TechnicalIndicators.simple_moving_average(prices, 5)
print(f"SMA(5): {sma_5}")

# ë³¼ë¦°ì € ë°´ë“œ
upper, middle, lower = TechnicalIndicators.bollinger_bands(prices, period=10)
print(f"ë³¼ë¦°ì €ë°´ë“œ: ìƒë‹¨={upper:.0f}, ì¤‘ê°„={middle:.0f}, í•˜ë‹¨={lower:.0f}")

# RSI
rsi_value = TechnicalIndicators.rsi(prices, period=14)
print(f"RSI(14): {rsi_value:.2f}")
```

---

## ğŸ’¾ ë°ì´í„° ë°±ì—… ë° ê´€ë¦¬

### ë‚ ì§œë³„ DB ë¶„ë¦¬ ì‹œìŠ¤í…œ (`utility/query.py:343-383`)

STOMì€ ë‹¹ì¼ ê±°ë˜ ì¢…ë£Œ í›„ ë°ì´í„°ë¥¼ ë‚ ì§œë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤:

```
_database/stock_tick.db (ë‹¹ì¼ ê±°ë˜ ë°ì´í„°)
  â†“ ì¼ìDBë¶„ë¦¬
_database/stock_tick_20240101.db
_database/stock_tick_20240102.db
_database/stock_tick_20240103.db
...
```

**ë°±í…ŒDBìƒì„±** (`utility/query.py:222-256`):
ë‚ ì§œë³„ DB íŒŒì¼ë“¤ì„ í•˜ë‚˜ì˜ ë°±í…ŒìŠ¤íŠ¸ìš© DBë¡œ í†µí•©:
```
stock_tick_20240101.db + stock_tick_20240102.db + ...
  â†“ ë°±í…ŒDBìƒì„±
stock_tick_back.db (ë°±í…ŒìŠ¤íŠ¸ìš© í†µí•© DB)
```

### ë°ì´í„° ì••ì¶• ì‹œìŠ¤í…œ (í•™ìŠµìš© ì˜ˆì œ)

ì˜¤ë˜ëœ ë°ì´í„°ë¥¼ ì••ì¶•í•˜ì—¬ ì €ì¥ ê³µê°„ì„ ì ˆì•½í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤:

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
import io
import pandas as pd
from datetime import datetime, timedelta

class DataCompressor:
    """ë°ì´í„° ì••ì¶• ê´€ë¦¬ - ì €ì¥ ê³µê°„ ìµœì í™”"""

    def __init__(self):
        # ë°ì´í„° ìœ í˜•ë³„ ì••ì¶• ë° ë³´ê´€ ê·œì¹™
        self.compression_rules = {
            'tick_data': {
                'retention_days': 30,           # 30ì¼ê°„ ë³´ê´€
                'compression_after_days': 7     # 7ì¼ í›„ ì••ì¶•
            },
            'minute_data': {
                'retention_days': 365,          # 1ë…„ê°„ ë³´ê´€
                'compression_after_days': 30    # 30ì¼ í›„ ì••ì¶•
            },
            'daily_data': {
                'retention_days': 3650,         # 10ë…„ê°„ ë³´ê´€
                'compression_after_days': 365   # 1ë…„ í›„ ì••ì¶•
            }
        }

    def compress_old_data(self, data_type, db_manager):
        """
        ì˜¤ë˜ëœ ë°ì´í„° ì••ì¶•

        Args:
            data_type: ë°ì´í„° ìœ í˜• ('tick_data', 'minute_data', etc.)
            db_manager: ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ì
        """
        rules = self.compression_rules.get(data_type)
        if not rules:
            return

        # ì••ì¶• ëŒ€ìƒ ë‚ ì§œ ê³„ì‚°
        cutoff_date = datetime.now() - timedelta(days=rules['compression_after_days'])

        # ì••ì¶• ëŒ€ìƒ ë°ì´í„° ì¡°íšŒ
        query = f"""
        SELECT * FROM {data_type}
        WHERE timestamp < ? AND compressed = 0
        ORDER BY timestamp
        """

        data = db_manager.execute_query(query, (cutoff_date,))

        if data:
            # ë°ì´í„° ì••ì¶• ë° ì €ì¥
            compressed_data = self.compress_data_chunk(data)
            self.save_compressed_data(data_type, compressed_data)

            # ì›ë³¸ ë°ì´í„° ì‚­ì œ ë˜ëŠ” ì••ì¶• í”Œë˜ê·¸ ì„¤ì •
            self.mark_as_compressed(data_type, cutoff_date)

    def compress_data_chunk(self, data):
        """
        ë°ì´í„° ì²­í¬ ì••ì¶• - Parquet í¬ë§· + gzip

        Parquet ì¥ì :
        - ì»¬ëŸ¼ ê¸°ë°˜ ì €ì¥ (SQL ì¿¼ë¦¬ ìµœì í™”)
        - íš¨ìœ¨ì ì¸ ì••ì¶•
        - ë©”íƒ€ë°ì´í„° í¬í•¨
        """
        # pandas DataFrameìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame(data)

        # Parquet í˜•ì‹ìœ¼ë¡œ ì••ì¶• (gzip)
        buffer = io.BytesIO()
        df.to_parquet(buffer, compression='gzip', engine='pyarrow')

        return buffer.getvalue()

    def decompress_data_chunk(self, compressed_data):
        """ì••ì¶• ë°ì´í„° í•´ì œ"""
        buffer = io.BytesIO(compressed_data)
        df = pd.read_parquet(buffer)

        return df.to_dict('records')

    def mark_as_compressed(self, data_type, cutoff_date):
        """ì••ì¶• í”Œë˜ê·¸ ì„¤ì •"""
        query = f"""
        UPDATE {data_type}
        SET compressed = 1
        WHERE timestamp < ?
        """
        # DB ì—…ë°ì´íŠ¸ ì‹¤í–‰

# ì‚¬ìš© ì˜ˆì‹œ
compressor = DataCompressor()

# 7ì¼ ì´ìƒëœ í‹± ë°ì´í„° ì••ì¶•
compressor.compress_old_data('tick_data', db_manager)
```

### ë°ì´í„° ì•„ì¹´ì´ë¹™ (í•™ìŠµìš© ì˜ˆì œ)

ì¥ê¸° ë³´ê´€ì„ ìœ„í•œ ë°ì´í„° ì•„ì¹´ì´ë¹™ ì‹œìŠ¤í…œ ì˜ˆì œì…ë‹ˆë‹¤:

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
import os
from datetime import datetime
import pandas as pd

class DataArchiver:
    """ë°ì´í„° ì•„ì¹´ì´ë¹™ ê´€ë¦¬ - ì¥ê¸° ë³´ê´€"""

    def __init__(self, archive_path="archive/"):
        self.archive_path = archive_path
        self.ensure_archive_directory()

    def ensure_archive_directory(self):
        """ì•„ì¹´ì´ë¸Œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        os.makedirs(self.archive_path, exist_ok=True)

    def archive_old_data(self, data_type, retention_days, db_manager):
        """
        ì˜¤ë˜ëœ ë°ì´í„° ì•„ì¹´ì´ë¹™

        Args:
            data_type: ë°ì´í„° ìœ í˜•
            retention_days: ë³´ê´€ ê¸°ê°„ (ì¼)
            db_manager: ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ì
        """
        cutoff_date = datetime.now() - timedelta(days=retention_days)

        # ì•„ì¹´ì´ë¹™ ëŒ€ìƒ ë°ì´í„° ì¡°íšŒ
        query = f"""
        SELECT * FROM {data_type}
        WHERE timestamp < ?
        ORDER BY timestamp
        """

        data = db_manager.execute_query(query, (cutoff_date,))

        if data:
            # ì›”ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì•„ì¹´ì´ë¹™
            grouped_data = self.group_by_month(data)

            for month_key, month_data in grouped_data.items():
                archive_file = f"{self.archive_path}/{data_type}_{month_key}.parquet.gz"
                self.save_archive_file(archive_file, month_data)

            # ì•„ì¹´ì´ë¹™ëœ ë°ì´í„° ì‚­ì œ
            self.delete_archived_data(data_type, cutoff_date, db_manager)

    def group_by_month(self, data):
        """
        ì›”ë³„ ë°ì´í„° ê·¸ë£¹í™”

        Returns:
            dict: {month_key: data_list}
            month_key í˜•ì‹: '2024_01', '2024_02', ...
        """
        grouped = {}

        for record in data:
            timestamp = record['timestamp']
            month_key = timestamp.strftime('%Y_%m')

            if month_key not in grouped:
                grouped[month_key] = []

            grouped[month_key].append(record)

        return grouped

    def save_archive_file(self, archive_file, data):
        """
        ì•„ì¹´ì´ë¸Œ íŒŒì¼ ì €ì¥

        Args:
            archive_file: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
            data: ì €ì¥í•  ë°ì´í„°
        """
        df = pd.DataFrame(data)
        df.to_parquet(archive_file, compression='gzip', engine='pyarrow')
        print(f"ì•„ì¹´ì´ë¸Œ ì €ì¥: {archive_file} ({len(data)} rows)")

    def restore_archived_data(self, data_type, start_date, end_date):
        """
        ì•„ì¹´ì´ë¹™ëœ ë°ì´í„° ë³µì›

        Args:
            data_type: ë°ì´í„° ìœ í˜•
            start_date: ì‹œì‘ ë‚ ì§œ
            end_date: ì¢…ë£Œ ë‚ ì§œ

        Returns:
            list: ë³µì›ëœ ë°ì´í„°
        """
        restored_data = []

        # í•´ë‹¹ ê¸°ê°„ì˜ ì•„ì¹´ì´ë¸Œ íŒŒì¼ ì°¾ê¸°
        archive_files = self.find_archive_files(data_type, start_date, end_date)

        for archive_file in archive_files:
            # ì•„ì¹´ì´ë¸Œ íŒŒì¼ ë¡œë“œ
            df = pd.read_parquet(archive_file)

            # ë‚ ì§œ ë²”ìœ„ í•„í„°ë§
            mask = (df['timestamp'] >= start_date) & (df['timestamp'] <= end_date)
            filtered_df = df[mask]

            restored_data.extend(filtered_df.to_dict('records'))

        return restored_data

    def find_archive_files(self, data_type, start_date, end_date):
        """
        ì•„ì¹´ì´ë¸Œ íŒŒì¼ ê²€ìƒ‰

        Returns:
            list: ì•„ì¹´ì´ë¸Œ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        archive_files = []

        # start_date ~ end_date ì‚¬ì´ì˜ ì›” ë¦¬ìŠ¤íŠ¸ ìƒì„±
        current = start_date.replace(day=1)
        while current <= end_date:
            month_key = current.strftime('%Y_%m')
            archive_file = f"{self.archive_path}/{data_type}_{month_key}.parquet.gz"

            if os.path.exists(archive_file):
                archive_files.append(archive_file)

            # ë‹¤ìŒ ë‹¬ë¡œ ì´ë™
            if current.month == 12:
                current = current.replace(year=current.year + 1, month=1)
            else:
                current = current.replace(month=current.month + 1)

        return archive_files

# ì‚¬ìš© ì˜ˆì‹œ
archiver = DataArchiver(archive_path="./archive")

# 1ë…„ ì´ìƒëœ ë°ì´í„° ì•„ì¹´ì´ë¹™
archiver.archive_old_data('tick_data', retention_days=365, db_manager=db_manager)

# ì•„ì¹´ì´ë¹™ëœ ë°ì´í„° ë³µì›
start = datetime(2023, 1, 1)
end = datetime(2023, 3, 31)
restored = archiver.restore_archived_data('tick_data', start, end)
print(f"ë³µì›ëœ ë°ì´í„°: {len(restored)} rows")
```

### ë°ì´í„° ì •ë¦¬ ê¸°ëŠ¥

- **ì§€ì •ì‹œê°„ì´í›„ì‚­ì œ**: íŠ¹ì • ì‹œê°„ ì´í›„ ë°ì´í„° ì‚­ì œ (í…ŒìŠ¤íŠ¸/ë””ë²„ê¹…ìš©)
- **VACUUM**: SQLite DB íŒŒì¼ í¬ê¸° ìµœì í™”

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
# VACUUM ì˜ˆì œ
import sqlite3
conn = sqlite3.connect('database/stock_tick.db')
conn.execute('VACUUM')  # ì‚­ì œëœ ë°ì´í„° ê³µê°„ íšŒìˆ˜
conn.close()
```

---

## ğŸ” ë°ì´í„° ì¡°íšŒ ë° í™œìš©

### ë°±í…ŒìŠ¤íŒ… ì‹œìŠ¤í…œ ë°ì´í„° ë¡œë”©

ë°±í…ŒìŠ¤íŒ… ì—”ì§„(`backtester/backengine_*.py`)ì€ ë‹¤ìŒê³¼ ê°™ì´ ë°ì´í„°ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤:

**ì¢…ëª©ë³„ ë¶„ë¥˜ ë°©ì‹** (ê¸°ë³¸):

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
# ê° ì¢…ëª©ì˜ ì „ì²´ ê¸°ê°„ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ë¡œë”©
con = sqlite3.connect(DB_STOCK_BACK_TICK)
df = pd.read_sql(f'SELECT * FROM "{code}" WHERE `index` LIKE "{day}%"', con)
```

**ì¼ìë³„ ë¶„ë¥˜ ë°©ì‹** (ë©”ëª¨ë¦¬ íš¨ìœ¨ì ):

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
# ê° ë‚ ì§œë³„ë¡œ ëª¨ë“  ì¢…ëª© ë°ì´í„° ë¡œë”©
con = sqlite3.connect(f'{DB_PATH}/stock_tick_{day}.db')
df = pd.read_sql(f'SELECT * FROM "{code}"', con)
```

### ê³ ì„±ëŠ¥ ë°ì´í„° ì¡°íšŒ (í•™ìŠµìš© ì˜ˆì œ)

ì¸ë±ìŠ¤ ìµœì í™”ì™€ ìºì‹±ì„ í™œìš©í•œ ê³ ì„±ëŠ¥ ì¡°íšŒ ì˜ˆì œì…ë‹ˆë‹¤:

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
import sqlite3
from datetime import datetime, timedelta

class DataQueryOptimizer:
    """ë°ì´í„° ì¡°íšŒ ìµœì í™” - ì¸ë±ìŠ¤ì™€ ìºì‹± í™œìš©"""

    def __init__(self, db_manager):
        self.db_manager = db_manager
        self.query_cache = {}  # {cache_key: result}
        self.max_cache_size = 1000

    def get_ohlcv_data(self, symbol, timeframe, start_date, end_date, limit=None):
        """
        OHLCV ë°ì´í„° ì¡°íšŒ - ìºì‹± ì§€ì›

        Args:
            symbol: ì¢…ëª©ì½”ë“œ
            timeframe: ì‹œê°„í”„ë ˆì„ ('1m', '5m', '1h', etc.)
            start_date: ì‹œì‘ ë‚ ì§œ
            end_date: ì¢…ë£Œ ë‚ ì§œ
            limit: ìµœëŒ€ í–‰ ìˆ˜

        Returns:
            list: [(timestamp, open, high, low, close, volume), ...]
        """
        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = f"{symbol}_{timeframe}_{start_date}_{end_date}_{limit}"

        # ìºì‹œ í™•ì¸
        if cache_key in self.query_cache:
            return self.query_cache[cache_key]

        # SQL ì¿¼ë¦¬ (ì¸ë±ìŠ¤ í™œìš©)
        query = """
        SELECT timestamp, open_price, high_price, low_price, close_price, volume
        FROM ohlcv_data
        WHERE symbol = ? AND timeframe = ?
        AND timestamp BETWEEN ? AND ?
        ORDER BY timestamp ASC
        """

        params = [symbol, timeframe, start_date, end_date]

        if limit:
            query += " LIMIT ?"
            params.append(limit)

        result = self.db_manager.execute_query(query, params)

        # ê²°ê³¼ ìºì‹± (ìµœëŒ€ ìºì‹œ í¬ê¸° ì œí•œ)
        if len(self.query_cache) < self.max_cache_size:
            self.query_cache[cache_key] = result

        return result

    def get_latest_tick_data(self, symbols, limit=100):
        """
        ìµœì‹  í‹± ë°ì´í„° ì¡°íšŒ - Window Function í™œìš©

        ê° ì¢…ëª©ì˜ ìµœì‹  Nê°œ í‹± ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì¡°íšŒ

        Args:
            symbols: ì¢…ëª©ì½”ë“œ ë¦¬ìŠ¤íŠ¸
            limit: ì¢…ëª©ë‹¹ ìµœëŒ€ í–‰ ìˆ˜

        Returns:
            list: í‹± ë°ì´í„°
        """
        # IN ì ˆì„ ìœ„í•œ í”Œë ˆì´ìŠ¤í™€ë”
        placeholders = ','.join(['?' for _ in symbols])

        # Window Functionì„ ì‚¬ìš©í•œ ROW_NUMBER
        query = f"""
        SELECT * FROM (
            SELECT *,
                   ROW_NUMBER() OVER (
                       PARTITION BY code
                       ORDER BY timestamp DESC
                   ) as rn
            FROM stock_tick
            WHERE code IN ({placeholders})
        )
        WHERE rn <= ?
        ORDER BY code, timestamp DESC
        """

        params = symbols + [limit]
        return self.db_manager.execute_query(query, params)

    def get_volume_profile(self, symbol, start_date, end_date, price_bins=50):
        """
        ê±°ë˜ëŸ‰ í”„ë¡œíŒŒì¼ ì¡°íšŒ - ê°€ê²©ëŒ€ë³„ ê±°ë˜ëŸ‰ ë¶„ì„

        Args:
            symbol: ì¢…ëª©ì½”ë“œ
            start_date: ì‹œì‘ ë‚ ì§œ
            end_date: ì¢…ë£Œ ë‚ ì§œ
            price_bins: ê°€ê²© êµ¬ê°„ ìˆ˜

        Returns:
            list: [(price_level, total_volume, tick_count), ...]
        """
        # ê°€ê²© ë²”ìœ„ ì¡°íšŒ
        price_query = """
        SELECT MIN(current_price) as min_price, MAX(current_price) as max_price
        FROM stock_tick
        WHERE code = ?
        """
        price_data = self.db_manager.execute_query(price_query, [symbol])
        min_price, max_price = price_data[0]

        # ê°€ê²© êµ¬ê°„ í¬ê¸° ê³„ì‚°
        bin_size = (max_price - min_price) / price_bins

        # ê±°ë˜ëŸ‰ í”„ë¡œíŒŒì¼ ì¿¼ë¦¬
        query = """
        SELECT
            ROUND(current_price / ?) * ? as price_level,
            SUM(volume) as total_volume,
            COUNT(*) as tick_count
        FROM stock_tick
        WHERE code = ? AND timestamp BETWEEN ? AND ?
        GROUP BY price_level
        ORDER BY price_level
        """

        params = [bin_size, bin_size, symbol, start_date, end_date]
        return self.db_manager.execute_query(query, params)

# ì‚¬ìš© ì˜ˆì‹œ
query_optimizer = DataQueryOptimizer(db_manager)

# OHLCV ë°ì´í„° ì¡°íšŒ
symbol = '005930'
timeframe = '1m'
start = datetime(2024, 1, 1, 9, 0, 0)
end = datetime(2024, 1, 1, 15, 30, 0)

ohlcv_data = query_optimizer.get_ohlcv_data(symbol, timeframe, start, end, limit=100)

# ìµœì‹  í‹± ë°ì´í„° ì¡°íšŒ (ì—¬ëŸ¬ ì¢…ëª©)
symbols = ['005930', '000660', '035720']
latest_ticks = query_optimizer.get_latest_tick_data(symbols, limit=10)

# ê±°ë˜ëŸ‰ í”„ë¡œíŒŒì¼ ì¡°íšŒ
volume_profile = query_optimizer.get_volume_profile(
    symbol='005930',
    start_date=datetime(2024, 1, 1),
    end_date=datetime(2024, 1, 31),
    price_bins=50
)
```

### ë°ì´í„° ë¶„ì„ ë„êµ¬ (í•™ìŠµìš© ì˜ˆì œ)

í†µê³„ ë¶„ì„ ë° ê¸°ìˆ ì  ë¶„ì„ ë„êµ¬ ì˜ˆì œì…ë‹ˆë‹¤:

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
import numpy as np
from datetime import datetime, timedelta

class DataAnalyzer:
    """ë°ì´í„° ë¶„ì„ ë„êµ¬ - í†µê³„ ë° ê¸°ìˆ ì  ë¶„ì„"""

    def __init__(self, query_optimizer):
        self.query_optimizer = query_optimizer

    def calculate_volatility(self, symbol, timeframe, period_days=30):
        """
        ë³€ë™ì„± ê³„ì‚° - ì—°ìœ¨í™” í‘œì¤€í¸ì°¨

        ë³€ë™ì„±(Volatility) = Ïƒ Ã— âˆš252
        - Ïƒ: ì¼ì¼ ìˆ˜ìµë¥ ì˜ í‘œì¤€í¸ì°¨
        - 252: ì—°ê°„ ê±°ë˜ì¼ìˆ˜

        Args:
            symbol: ì¢…ëª©ì½”ë“œ
            timeframe: ì‹œê°„í”„ë ˆì„
            period_days: ê³„ì‚° ê¸°ê°„ (ì¼)

        Returns:
            float: ì—°ìœ¨í™” ë³€ë™ì„± (%)
        """
        end_date = datetime.now()
        start_date = end_date - timedelta(days=period_days)

        # OHLCV ë°ì´í„° ì¡°íšŒ
        data = self.query_optimizer.get_ohlcv_data(
            symbol, timeframe, start_date, end_date
        )

        if len(data) < 2:
            return None

        # ì¼ì¼ ìˆ˜ìµë¥  ê³„ì‚°
        returns = []
        for i in range(1, len(data)):
            prev_close = data[i-1][4]  # close_price
            curr_close = data[i][4]
            daily_return = (curr_close - prev_close) / prev_close
            returns.append(daily_return)

        # ì—°ìœ¨í™” ë³€ë™ì„± ê³„ì‚°
        volatility = np.std(returns) * np.sqrt(252) * 100  # %ë¡œ í‘œì‹œ

        return volatility

    def calculate_correlation(self, symbol1, symbol2, timeframe, period_days=30):
        """
        ìƒê´€ê´€ê³„ ê³„ì‚° - í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜

        ìƒê´€ê³„ìˆ˜:
        - +1: ì™„ì „ ì–‘ì˜ ìƒê´€ê´€ê³„
        -  0: ìƒê´€ê´€ê³„ ì—†ìŒ
        - -1: ì™„ì „ ìŒì˜ ìƒê´€ê´€ê³„

        Args:
            symbol1: ì²« ë²ˆì§¸ ì¢…ëª©
            symbol2: ë‘ ë²ˆì§¸ ì¢…ëª©
            timeframe: ì‹œê°„í”„ë ˆì„
            period_days: ê³„ì‚° ê¸°ê°„

        Returns:
            float: ìƒê´€ê³„ìˆ˜ (-1 ~ 1)
        """
        end_date = datetime.now()
        start_date = end_date - timedelta(days=period_days)

        # ë‘ ì¢…ëª©ì˜ OHLCV ë°ì´í„° ì¡°íšŒ
        data1 = self.query_optimizer.get_ohlcv_data(symbol1, timeframe, start_date, end_date)
        data2 = self.query_optimizer.get_ohlcv_data(symbol2, timeframe, start_date, end_date)

        # ê³µí†µ ì‹œê°„ëŒ€ ë°ì´í„° ì¶”ì¶œ
        common_data = self.align_time_series(data1, data2)

        if len(common_data['data1']) < 10:
            return None

        # ì¢…ê°€ ì¶”ì¶œ
        prices1 = np.array([row[4] for row in common_data['data1']])
        prices2 = np.array([row[4] for row in common_data['data2']])

        # í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ê³„ì‚°
        correlation = np.corrcoef(prices1, prices2)[0, 1]

        return correlation

    def align_time_series(self, data1, data2):
        """
        ì‹œê³„ì—´ ë°ì´í„° ì •ë ¬ - ê³µí†µ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ

        Returns:
            dict: {'data1': [...], 'data2': [...]}
        """
        # íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        dict1 = {row[0]: row for row in data1}
        dict2 = {row[0]: row for row in data2}

        # ê³µí†µ íƒ€ì„ìŠ¤íƒ¬í”„
        common_timestamps = sorted(set(dict1.keys()) & set(dict2.keys()))

        # ê³µí†µ ë°ì´í„° ì¶”ì¶œ
        aligned_data1 = [dict1[ts] for ts in common_timestamps]
        aligned_data2 = [dict2[ts] for ts in common_timestamps]

        return {'data1': aligned_data1, 'data2': aligned_data2}

    def detect_support_resistance(self, symbol, timeframe, period_days=90, tolerance=0.02):
        """
        ì§€ì§€/ì €í•­ì„  íƒì§€ - ê°€ê²© í´ëŸ¬ìŠ¤í„° ë¶„ì„

        Args:
            symbol: ì¢…ëª©ì½”ë“œ
            timeframe: ì‹œê°„í”„ë ˆì„
            period_days: ë¶„ì„ ê¸°ê°„
            tolerance: ê°€ê²© í—ˆìš© ì˜¤ì°¨ (2% = 0.02)

        Returns:
            dict: {'support_levels': [...], 'resistance_levels': [...]}
        """
        end_date = datetime.now()
        start_date = end_date - timedelta(days=period_days)

        # OHLCV ë°ì´í„° ì¡°íšŒ
        data = self.query_optimizer.get_ohlcv_data(symbol, timeframe, start_date, end_date)

        # ê³ ê°€/ì €ê°€ ì¶”ì¶œ
        highs = [row[2] for row in data]  # high_price
        lows = [row[3] for row in data]   # low_price

        # ì§€ì§€ì„  (ì €ì  í´ëŸ¬ìŠ¤í„°)
        support_levels = self.find_price_clusters(lows, tolerance)

        # ì €í•­ì„  (ê³ ì  í´ëŸ¬ìŠ¤í„°)
        resistance_levels = self.find_price_clusters(highs, tolerance)

        return {
            'support_levels': support_levels,
            'resistance_levels': resistance_levels
        }

    def find_price_clusters(self, prices, tolerance=0.02):
        """
        ê°€ê²© í´ëŸ¬ìŠ¤í„° ì°¾ê¸° - ë¹„ìŠ·í•œ ê°€ê²©ëŒ€ ê·¸ë£¹í™”

        Args:
            prices: ê°€ê²© ë¦¬ìŠ¤íŠ¸
            tolerance: í—ˆìš© ì˜¤ì°¨ ë¹„ìœ¨

        Returns:
            list: [{'level': í‰ê· ê°€ê²©, 'strength': í„°ì¹˜íšŸìˆ˜, 'prices': [...]}, ...]
        """
        clusters = []
        sorted_prices = sorted(prices)

        if not sorted_prices:
            return clusters

        current_cluster = [sorted_prices[0]]

        for price in sorted_prices[1:]:
            # í˜„ì¬ í´ëŸ¬ìŠ¤í„°ì˜ ë§ˆì§€ë§‰ ê°€ê²©ê³¼ ë¹„êµ
            if abs(price - current_cluster[-1]) / current_cluster[-1] <= tolerance:
                current_cluster.append(price)
            else:
                # í´ëŸ¬ìŠ¤í„° ì™„ì„± (ìµœì†Œ 3íšŒ í„°ì¹˜)
                if len(current_cluster) >= 3:
                    clusters.append({
                        'level': np.mean(current_cluster),
                        'strength': len(current_cluster),
                        'prices': current_cluster.copy()
                    })
                current_cluster = [price]

        # ë§ˆì§€ë§‰ í´ëŸ¬ìŠ¤í„° ì²˜ë¦¬
        if len(current_cluster) >= 3:
            clusters.append({
                'level': np.mean(current_cluster),
                'strength': len(current_cluster),
                'prices': current_cluster
            })

        # ê°•ë„(í„°ì¹˜ íšŸìˆ˜)ìˆœìœ¼ë¡œ ì •ë ¬
        return sorted(clusters, key=lambda x: x['strength'], reverse=True)

# ì‚¬ìš© ì˜ˆì‹œ
analyzer = DataAnalyzer(query_optimizer)

# ë³€ë™ì„± ê³„ì‚°
volatility = analyzer.calculate_volatility('005930', '1d', period_days=30)
print(f"30ì¼ ë³€ë™ì„±: {volatility:.2f}%")

# ìƒê´€ê´€ê³„ ê³„ì‚° (ì‚¼ì„±ì „ì vs SKí•˜ì´ë‹‰ìŠ¤)
correlation = analyzer.calculate_correlation('005930', '000660', '1d', period_days=60)
print(f"ìƒê´€ê³„ìˆ˜: {correlation:.3f}")

# ì§€ì§€/ì €í•­ì„  íƒì§€
levels = analyzer.detect_support_resistance('005930', '1d', period_days=90, tolerance=0.02)
print(f"ì£¼ìš” ì§€ì§€ì„ : {[l['level'] for l in levels['support_levels'][:3]]}")
print(f"ì£¼ìš” ì €í•­ì„ : {[l['level'] for l in levels['resistance_levels'][:3]]}")
```

### ì‹¤ì‹œê°„ ë°ì´í„° í™œìš©

ë¦¬ì‹œë²„ â†’ ì „ëµ â†’ íŠ¸ë ˆì´ë”ë¡œ ë°ì´í„° ì „ì†¡:

**ì†ŒìŠ¤**: ì˜ˆì œ ì½”ë“œ

```python
# ë¦¬ì‹œë²„: ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì‹  ë° ì „ì²˜ë¦¬
# â†“ Queueë¥¼ í†µí•´ ì „ì†¡
# ì „ëµ: ë§¤ë§¤ ì‹œê·¸ë„ ìƒì„±
# â†“ Queueë¥¼ í†µí•´ ì „ì†¡
# íŠ¸ë ˆì´ë”: ì£¼ë¬¸ ì‹¤í–‰
```

---

*ë‹¤ìŒ: [07. íŠ¸ë ˆì´ë”© ì—”ì§„](../07_Trading/trading_engine.md)* 